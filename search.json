[{"path":"/articles/credential-scraping.html","id":"api-token-scraping-and-fabricating","dir":"Articles","previous_headings":"","what":"API Token Scraping and Fabricating","title":"Credential Scraping","text":"Using credential management tools requires .env files populated database credentials REDCap instance, following examples use one production instance (prod.env) one local instance (local_1134.env). local_1134.env file:","code":"INSTANCE=local_1134 TIME_ZONE=America/New_York  # REDCap API endpoint, REDCap webroot + \"/api/\" URI=https://localhost:11134/api/  # REDCap DB Credentials REDCAP_DB_NAME=redcap REDCAP_DB_HOST=127.0.0.1 REDCAP_DB_USER=redcap REDCAP_DB_PASSWORD=redcap123 REDCAP_DB_PORT=3306"},{"path":"/articles/credential-scraping.html","id":"preparation","dir":"Articles","previous_headings":"API Token Scraping and Fabricating","what":"Preparation","title":"Credential Scraping","text":"following block creates credentials directory sqlite database store credentials.","code":"library(redcapcustodian) library(DBI) library(tidyverse) library(dotenv)  # fetching all extant API tokens and adding them to storage #################  dir.create(\"credentials\")  # creates file if one does not exist file_conn <- DBI::dbConnect(RSQLite::SQLite(), \"credentials/credentials.db\")  # SQLite friendly schema credentials_sql <- \"CREATE TABLE IF NOT EXISTS `credentials` (   `redcap_uri` TEXT NOT NULL,   `server_short_name` varchar(128) NOT NULL,   `username` varchar(191) NOT NULL,   `project_id` int(10) NOT NULL,   `project_display_name` TEXT NOT NULL,   `project_short_name` varchar(128) DEFAULT NULL,   `token` varchar(64) NOT NULL,   `comment` varchar(256) DEFAULT NULL ); \"  dbExecute(file_conn, credentials_sql)"},{"path":"/articles/credential-scraping.html","id":"scraping-a-servers-api-tokens-and-putting-them-in-a-local-sqlite-db-for-use","dir":"Articles","previous_headings":"API Token Scraping and Fabricating","what":"Scraping a server’s API tokens and putting them in a local sqlite DB for use","title":"Credential Scraping","text":"Fetching extant API tokens adding storage","code":"library(redcapcustodian) library(DBI) library(tidyverse) library(dotenv)  # fetching all extant API tokens and adding them to storage #################  file_conn <- DBI::dbConnect(RSQLite::SQLite(), \"credentials/credentials.db\")  dbExecute(file_conn, credentials_sql)  load_dot_env(\"prod.env\")  username <- \"your_redcap_username\" source_conn <- connect_to_redcap_db() source_credentials <- scrape_user_api_tokens(source_conn, username)  # alter credentials to match local schema source_credentials_upload <- source_credentials %>%   mutate(     redcap_uri = Sys.getenv(\"URI\"),     server_short_name = tolower(Sys.getenv(\"INSTANCE\"))   ) %>%   # remove duplicates   anti_join(     tbl(file_conn, \"credentials\") %>%       collect()   )  dbAppendTable(file_conn, \"credentials\", source_credentials_upload)"},{"path":"/articles/credential-scraping.html","id":"creating-api-tokens-for-all-local-projects","dir":"Articles","previous_headings":"API Token Scraping and Fabricating","what":"Creating API tokens for all local projects","title":"Credential Scraping","text":"","code":"library(redcapcustodian) library(DBI) library(tidyverse) library(dotenv)  file_conn <- DBI::dbConnect(RSQLite::SQLite(), \"credentials/credentials.db\")  load_dot_env(\"local_1134.env\")  # note, this will close any other connections target_conn <- connect_to_redcap_db()  local_credentials <- scrape_user_api_tokens(target_conn, \"admin\")  # specify a subset of project_ids rather than making tokens for all target_pids <- tbl(target_conn, \"redcap_projects\") %>%   select(project_id) %>%   filter(project_id > 15) %>%   filter(!project_id %in% local(local_credentials$project_id)) %>%   collect() %>%   pull(project_id)  # create tokens individually for(pid in target_pids) {   set_project_api_token(target_conn, \"admin\", pid) }  # gather newly created tokens and insert them into local storage local_credentials <- scrape_user_api_tokens(target_conn, \"admin\")  local_credentials_upload <- local_credentials %>%   mutate(     redcap_uri = Sys.getenv(\"URI\"),     server_short_name = tolower(Sys.getenv(\"INSTANCE\"))   ) %>%   # remove duplicates   anti_join(     tbl(file_conn, \"credentials\") %>%       collect()   )  dbAppendTable(file_conn, \"credentials\", local_credentials_upload)"},{"path":"/articles/credential-scraping.html","id":"syncing-a-production-project-to-your-local-instance","dir":"Articles","previous_headings":"","what":"Syncing a production project to your local instance","title":"Credential Scraping","text":"completing previous 2 sections. following chink uses credentials saved copy project metadata source project ()","code":"library(redcapcustodian) library(tidyverse)  file_conn <- DBI::dbConnect(RSQLite::SQLite(), \"credentials/credentials.db\")  source_username <- \"your_production_username\"  source_credentials <- tbl(file_conn, \"credentials\") %>%   filter(source_username) %>%   filter(server_short_name == \"prod\") %>%   collect() %>%   filter(     str_detect(project_display_name, \"The big important project\")   ) %>%   unnest()  local_credentials <- tbl(file_conn, \"credentials\") %>%   filter(username == \"admin\") %>%   filter(server_short_name == \"local_1134\") %>%   collect() %>%   # adjust url to make REDCapR's validation processes happy   mutate(redcap_uri = str_replace(redcap_uri, \"https\", \"http\")) %>%   mutate(redcap_uri = str_replace(redcap_uri, \"localhost\", \"127.0.0.1\")) %>%   filter(     str_detect(project_display_name, \"The big important project\")   ) %>%   unnest()  sync_metadata(source_credentials, local_credentials, strip_action_tags = TRUE)"},{"path":"/articles/credential-scraping.html","id":"large-data-dictionaries-and-xdebugredcap-docker-compose","dir":"Articles","previous_headings":"Syncing a production project to your local instance","what":"Large data dictionaries and XDebug/REDCap Docker Compose","title":"Credential Scraping","text":"REDCap instance hosted machine (docker container) using xdebug, metadata may large, case ’ll see error message like : Alter following file <-rdc-instance>/redcap-overrides/web/php/80-xdebug.ini set arbitrarily large stack frame limit, least equal number fields data dictionary","code":"The REDCapR write/import metadata operation was not successful.  The error message was:\\n\\t\\t\\t\\t<div class=\\\"red\\\" style=\\\"margin:20px 0px;max-width:700px;\\\">\\n\\t\\t\\t\\t\\t<b>REDCap crashed due to an unexpected PHP fatal error!<\/b><br><br>\\n\\t\\t\\t\\t\\t<b>Error message:<\/b> Uncaught Error: Xdebug has detected a possible infinite loop, and aborted your script with a stack depth of '256' frames in /var/www/html/redcap_v11.3.4/Classes/LogicParser.php:280\\ # solution: https://stackoverflow.com/a/65997576/7418735 xdebug.max_nesting_level=<high-value>"},{"path":"/articles/custom_rscript.html","id":"writing-your-own-redcapcustodian-rscripts","dir":"Articles","previous_headings":"","what":"Writing your own redcapcustodian Rscripts","title":"Custom Rscript","text":"basic use, redcapcustodian need load library Rscript. automate report ETL already redcapcustodian, need build image, write configuration file instantiate container image config file. Yet allows extensive customization builds upon framework provides.","code":""},{"path":"/articles/custom_rscript.html","id":"writing-your-own-rscripts","dir":"Articles","previous_headings":"Writing your own redcapcustodian Rscripts","what":"Writing your own Rscripts","title":"Custom Rscript","text":"can write Rscript accomplish task one REDCap hosts projects. script load redcapcustodian package. make script clone redcap custodian repository, copy contents study_template new folder Rename Rstudio project match study’s name: can open new project Rstudio. first redcapcustodian project, might help follow example vignette(\"friday-call-demo\") RStudio. example created present REDCap Custodian REDCap community. first REDCap Custodian rodeo, might remember need , offer guide help avoid mis-steps.","code":"git clone git@github.com:ctsit/redcapcustodian.git cp -r redcapcustodian/site_template my.study cd ../my.study mv example.Rproj my.study.Rproj open my.study.Rproj"},{"path":"/articles/custom_rscript.html","id":"configure-your-interfaces","dir":"Articles","previous_headings":"Writing your own redcapcustodian Rscripts","what":"Configure your interfaces","title":"Custom Rscript","text":"’ll need talk least REDCap MySQL database. probably want . Rename example.env testing.env configure development computer. file composed five sections. INSTANCE names REDCap system instance ’ll talking . file assumes talking one REDCap script. tools multiple-instances. TIME_ZONE local timezone REDCap instance. Note REDCap time facts local time. MariaDB driver Lubridate library default UTC. can get complicated. careful time. details see stupid_date_tricks.R Many scripts need send emails developers, REDCap Admin study coordinator. Set email values appropriately site study needs. need talk directly REDCap database, ’ll need provide credentials database. development work, enter credentials local MySQL Database. task study working might need database tables. might hold data need REDCap data fit well REDCap data model. REDCap projects large (think 30K records ) might want mirror REDCap project MySQL run performant queries. describes need, best mix tables REDCap tables. second MySQL table credentials scripts need access secrets. “ETL” prefix nothing special, means “Extract, Transform, Load”–common term database management. can use prefix like, want use prefix. database connection functions depend . REDCap Custodian provides rich framework logging success failure automated processes. default, logs activity MySQL databse choosing. REDCap database. ’s completely reasonable log study’s activity study database, don’t study database, shared logging database good thing. Make sure set LOG_DB_ values.","code":"INSTANCE=Development TIME_ZONE=America/New_York # Email config EMAIL_TO=you@example.org EMAIL_CC= EMAIL_FROM=please-do-not-reply@example.org SMTP_SERVER=smtp.example.org # REDCap DB Credentials REDCAP_DB_NAME=DB_NAME REDCAP_DB_HOST=DB_HOST REDCAP_DB_USER=DB_USER REDCAP_DB_PASSWORD=DB_PASSWORD REDCAP_DB_PORT=3306 # ETL DB Credentials ETL_DB_NAME= ETL_DB_HOST= ETL_DB_USER= ETL_DB_PASSWORD= ETL_DB_SCHEMA= ETL_DB_PORT= # Log DB Credentials LOG_DB_NAME= LOG_DB_HOST= LOG_DB_USER= LOG_DB_PASSWORD= LOG_DB_SCHEMA= LOG_DB_PORT="},{"path":"/articles/custom_rscript.html","id":"redcap-api-credential-management","dir":"Articles","previous_headings":"Writing your own redcapcustodian Rscripts","what":"REDCap API credential management","title":"Custom Rscript","text":"’s possible credential management environment variables, quickly gets tedious. get’s tedious manage multiple API tokens. address , REDCap custodian provides credential management functions help make use local dataset REDCAp API credentials. See vignette(\"credential-scraping\") example . Read Scraping server’s API tokens putting local sqlite DB","code":""},{"path":"/articles/custom_rscript.html","id":"create-your-scripts-in-the-right-folder","dir":"Articles","previous_headings":"Writing your own redcapcustodian Rscripts","what":"Create your scripts in the right folder","title":"Custom Rscript","text":"Create scripts move clean data etl folder. Create reports reports folder. aren’t rules, useful conventions. excluded package build process make package code folders won’t cause warnings build.","code":""},{"path":"/articles/custom_rscript.html","id":"tiny-script-example","dir":"Articles","previous_headings":"Writing your own redcapcustodian Rscripts","what":"Tiny script example","title":"Custom Rscript","text":"REDCap custodian includes example report script describe REDCap users REDCap User Lifecycle. provides example report run REDCap system. also example report output University Florida CTSI REDCap system annotations explain tells history activity UF system.","code":""},{"path":"/articles/custom_rscript.html","id":"logging","dir":"Articles","previous_headings":"Writing your own redcapcustodian Rscripts","what":"Logging","title":"Custom Rscript","text":"REDCap Custodian provides valuable logging reduce stress running unattended jobs writing data important things. use logging need create MySQL/Maria DB, put credentials environment file described , load redcapcustodian package script, initialize logging. can also log success end script log warnings failure script can detect . ’s actual script makes changes redcap backend logs : script generated log record log database: job_summary_data JSON object data updated. ’s hard humans read 100% machine parsable. query job log, use favorite DB client. Tidyverse developer, dplyr::tbl() fantastic DB client.","code":"library(tidyverse) library(redcapcustodian) library(rcc.billing) library(DBI) library(dotenv)  init_etl(\"update_project_billable_attribute\")  conn <- connect_to_redcap_db()  diff_output <- update_billable_by_ownership(conn)  sync_activity <- redcapcustodian::sync_table(   conn = conn,   table_name = \"redcap_entity_project_ownership\",   primary_key = \"id\",   data_diff_output = diff_output,   insert = F,   update = T,   delete = F )  activity_log <- diff_output$update_records %>%   select(pid, billable, updated)  log_job_success(jsonlite::toJSON(activity_log)) INSERT INTO `rcc_job_log` (`job_duration`, `job_summary_data`, `level`, `log_date`, `script_name`, `script_run_time`) VALUES (80.16091799736023, '[{\\\"pid\\\":15,\\\"billable\\\":1,\\\"updated\\\":1657139254},{\\\"pid\\\":16,\\\"billable\\\":1,\\\"updated\\\":1657139254},{\\\"pid\\\":22,\\\"billable\\\":1,\\\"updated\\\":1657139254}]', 'SUCCESS', '2022-07-06 20:28:54.494426', 'update_project_billable_attribute', '2022-07-06 20:27:34.322926');"},{"path":"/articles/custom_rscript.html","id":"writing-good-data-management-code","dir":"Articles","previous_headings":"Writing your own redcapcustodian Rscripts","what":"Writing good data management code","title":"Custom Rscript","text":"big topic cover central entire effort can’t entirely ignored. best favor can customers, use good tools. CTS-, identified toolset allows us efficient programming. strongly recommend tools: R 99% data programming. RStudio easiest possible integrated development environment R programming. Tidyverse effective dialect R code . REDCapR 99% REDCap API access. DBI dplyr::tbl() access SQL tables. ’s also wise good software development workflow. CTS-use tools rules: Use version control code. one developer, code review everything. one developer, use Github workflow pull requests, review, merges manage code review. Never put secrets code. Put secrets environment variables, datasets, systems. Never put secrets version control. Don’t put configuration code. Instead put environment variables datasets. Stop think architecture study lifecycle. Don’t mix two studies one git repository. Don’t afraid make R package just one study. Think names things. Pick good names. Don’t afraid rename poorly named things.","code":""},{"path":"/articles/custom_rscript.html","id":"automation-with-container-infrastructure","dir":"Articles","previous_headings":"Writing your own redcapcustodian Rscripts","what":"Automation with container infrastructure","title":"Custom Rscript","text":"need something run periodically, need make easy run dependencies packaged need schedule . modern way package dependencies put container, add application run container. REDCap Custodian supports containerization Docker. ./study_template/Dockerfile template can use containerize RScript RMarkdown. Adapt needs build container ./build.sh. good container infrastructure, use build deploy containers. Running automated R Markdown reports docker requires use Rmd renderer. render_report.R contains functionality knit Rmd, email log job run. Rmd script name passed command line argument render_report.R via cron. Refer sample_report example cron job.","code":""},{"path":"/articles/custom_rscript.html","id":"automation-with-linux-and-cron","dir":"Articles","previous_headings":"Writing your own redcapcustodian Rscripts","what":"Automation with Linux and cron","title":"Custom Rscript","text":"container management infrastructure available , support provides Linux hosts, build one , install Docker , give sudo su access. allow build run docker images host. Login, git clone redcapcustodian’s git repository, cd repository build image: study repository: clone private repository, ’ll need deployment key. See Deploy Keys instructions. ’ve built study container Docker host, create cron entry run right parameters secrets. run script, etl/update_project_billable_attribute.R regularly host call ‘prod’, create cron entry : build script -d option automatically deploy cron file build time. place cron file ./cron/ folder root repository, build ./build.sh -d, build script copy file /etc/cron.d give guaranteed unique name.","code":"git clone git@github.com:ctsit/redcapcustodian.git cd redcapcustodian sudo ./build.sh git clone git@github.com:ctsit/rcc.billing.git cd rcc.billing sudo ./build.sh sudo su cat <<END>> prod/cron/update_project_billable_attribute # run update_project_billable_attribute at 6:07 a.m. 7 6 * * * root /usr/bin/docker run --rm --env-file /rcc/rcc.billing/prod.env rcc.billing Rscript rcc.billing/etl/update_project_billable_attribute.R END"},{"path":"/articles/custom_rscript.html","id":"using-version-control","dir":"Articles","previous_headings":"Writing your own redcapcustodian Rscripts","what":"Using version control","title":"Custom Rscript","text":"go road writing scripts, concerned preserving . One best ways via git version control. Initialize new software repository ./.study folder. add remote pointing new empty repository GitHub, GitLab, BitBucket favorite Git repository hosting service, push new repo.","code":""},{"path":"/articles/custom_rscript.html","id":"adding-a-custom-package","dir":"Articles","previous_headings":"Writing your own redcapcustodian Rscripts","what":"Adding a custom package","title":"Custom Rscript","text":"want complex things redcapcustodian Rscripts share custom code , might want add R package just redcapcustodian work. redcapcustodian supports development package within ./.study/ folder. RStudio team’s packaging guidelines excellent guide package development. might seem like lot take , solve common problems. help write better code. don’t need submit package CRAN get value packaging guidelines. build latest version package build task container, uncomment lines task’s Dockerfile customize package name:","code":"# Add, build, and install this study's package ADD .. /home/rocker/my.study RUN R CMD build my.study RUN R CMD INSTALL my.study*.tar.gz RUN rm -rf my.study"},{"path":"/articles/developer_notes.html","id":"release-and-deployment","dir":"Articles","previous_headings":"","what":"Release and Deployment","title":"Developer Notes for REDCap Custodian","text":"project uses Git Flow workflow releases. Every release versioned ChangeLog entry describes new features bug fixes. Every release also accompanied updated VERSION manual revision version number DESCRIPTION. latter tells devtools version number changes. former allows image builds tagged built build.sh deploy new release Linux host, execute series commands equivalent home directory host:","code":"git clone git@github.com:ctsit/redcapcustodian.git cd redcapcustodian git pull sudo ./build.sh"},{"path":"/articles/developer_notes.html","id":"local-logging-for-development-work","dir":"Articles","previous_headings":"","what":"Local logging for development work","title":"Developer Notes for REDCap Custodian","text":"development work, ’s useful local log database. allows initialize logging test scripts without throwing error even test write log success failure. REDCap Custodian provides example logging system form docker-compose.yml database schema ./rcc.log.db/. can start logging database commands: default, PHPMyAdmin interface accessible http://localhost:9080/. configuration parameters defined ./rcc.log.db/.env. parameters used ./study_template/example.env. Using example values local environment files allow scripts across redcap custodian projects allow share logging database. =======","code":"cd ./rcc.log.db/ docker-compose up -d"},{"path":"/articles/friday-call-demo-setup.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"REDCap Custodian Friday Call Demo Credentials Setup","text":"setup instructions demonstration features REDCap Custodian R package. setup steps, demonstrate : Create local credentials database Fetch store API tokens credentials database Create load fake data REDCap projects want test . prelude demonstration moving data REDCap projects described vignette(\"friday-call-demo\").","code":""},{"path":"/articles/friday-call-demo-setup.html","id":"prequisites","dir":"Articles","previous_headings":"","what":"Prequisites","title":"REDCap Custodian Friday Call Demo Credentials Setup","text":"want , recommend things setup development testing environment: Install R, Rstudio, tidyverse packages Install redcapcustodian github Clone redcap-docker-compose git repo Create local REDCap redcap-docker-compose Create new project Rstudio. Note R project, REDCap project, Copy local.env.txt .env root new project folder. also need REDCap projects play . , ’s great. demo, need two REDCap projects exist. Please make projects XML files: main biospecimen. Name project main.xml: “Demo Main” Name project biospecimen.xml: “Demo Biospecimen” talk projects code, ’ll need API tokens. Add main biospecimen projects. project want play . changes place, can start developing scripts use REDCap Custodian.","code":""},{"path":"/articles/friday-call-demo-setup.html","id":"fetch-and-store-api-tokens","dir":"Articles","previous_headings":"","what":"Fetch and store API Tokens","title":"REDCap Custodian Friday Call Demo Credentials Setup","text":"First, load R packages: , make database hold credentials: Now, fetch API tokens write local credentials DB.","code":"library(redcapcustodian) library(DBI) library(tidyverse) library(dotenv) library(lubridate) dir.create(here::here(\"credentials\"))  # creates file if one does not exist file_conn <- DBI::dbConnect(RSQLite::SQLite(), here::here(\"credentials/credentials.db\"))  # SQLite friendly schema credentials_sql <- \"CREATE TABLE IF NOT EXISTS `credentials` (   `redcap_uri` TEXT NOT NULL,   `server_short_name` varchar(128) NOT NULL,   `username` varchar(191) NOT NULL,   `project_id` int(10) NOT NULL,   `project_display_name` TEXT NOT NULL,   `project_short_name` varchar(128) DEFAULT NULL,   `token` varchar(64) NOT NULL,   `comment` varchar(256) DEFAULT NULL ); \"  dbExecute(file_conn, credentials_sql) # fetching all extant API tokens and adding them to storage ################# load_dot_env(here::here(\"local.env.txt\"))  my_username <- \"admin\" source_conn <- connect_to_redcap_db() scraped_credentials <- scrape_user_api_tokens(source_conn, my_username)  # alter credentials to match local schema source_credentials_upload <- scraped_credentials %>%   mutate(     redcap_uri = Sys.getenv(\"URI\"),     server_short_name = tolower(Sys.getenv(\"INSTANCE\"))   ) %>%   # remove duplicates   anti_join(     tbl(file_conn, \"credentials\") %>%       collect()   )  dbAppendTable(file_conn, \"credentials\", source_credentials_upload)"},{"path":"/articles/friday-call-demo-setup.html","id":"make-test-data-and-write-it-to-your-test-projects","dir":"Articles","previous_headings":"","what":"Make test data and write it to your test projects","title":"REDCap Custodian Friday Call Demo Credentials Setup","text":"generate records main project port Biospecimen project. First, access credential database get credentials REDCap project want read . use Beasley’s REDCapR library interact REDCap via API. REDCapR allows specify forms, fields, event names, time frames interest. even allows REDCap filtering. isn’t necessary understand following block typically won’t populating project random data.","code":"source_credentials <- tbl(file_conn, \"credentials\") %>%   filter(username == my_username) %>%   collect() %>%   filter(str_detect(project_display_name, \"Demo Main\")) %>%   unnest() record_count_to_create <- 50 collection_events <- 5 tubes_per_collection <- 30  record_columns <- c(   \"record_id\",   \"redcap_event_name\",   \"sample_collected_date\",   \"tmp_event_id\",   paste0(\"tube_id\", 1:tubes_per_collection),   paste0(\"tube_specimen_type\", 1:tubes_per_collection),   paste0(\"tube_volume\", 1:tubes_per_collection)   )  # create empty dataframe and set column names simulated_data <- data.frame(   matrix(ncol = length(record_columns), nrow = 0) ) %>%   mutate(across(everything(), as.character)) colnames(simulated_data) <- record_columns  # create base entries for each event # NOTE: may be a bit slow as for-loops are not generally used in R for (record_id in 1:record_count_to_create) {   for (event_id in 1:collection_events) {     simulated_data <- simulated_data %>%       add_row(         record_id = as.character(record_id),         redcap_event_name = paste0(\"event_\", event_id, \"_arm_1\"),         tmp_event_id = as.character(event_id), # used to generate tube IDs later         sample_collected_date = sample(           seq(ymd(\"2020-03-01\"), ymd(\"2022-06-01\"), by = \"day\"), size = 1, replace = T         ) %>% as.character()       )   } }  # group to ensure simulated data is consistent with a single collection event simulated_data <- simulated_data %>%   group_by(record_id, redcap_event_name)  # simulate individual samples for (tube in 1:tubes_per_collection) {   simulated_data <- simulated_data %>%     mutate(       \"tube_id{tube}\" := paste0(         record_id, \"-\",         str_pad(tmp_event_id, width = 2, side = \"left\", pad = \"0\"), \"-\",         str_pad(tube, width = 2, side = \"left\", pad = \"0\")       ),       \"tube_specimen_type{tube}\" := sample(1:4, size = 1),       \"tube_volume{tube}\" := sample(2:4, size = 1)     ) }  # remove temporary column used in simulation simulated_data <- simulated_data %>%   ungroup() %>%   select(-tmp_event_id)  # upload data to REDCap REDCapR::redcap_write(   redcap_uri = source_credentials$redcap_uri,   token = source_credentials$token,   ds_to_write = simulated_data )"},{"path":"/articles/friday-call-demo.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"REDCap Custodian Friday Call Demo","text":"demonstration features REDCap Custodian R package. demonstrate : Fetch store API tokens database Get data REDCap project Transform data Write another project Review logs job ’ll talk automate whole process.","code":""},{"path":"/articles/friday-call-demo.html","id":"prequisites","dir":"Articles","previous_headings":"","what":"Prequisites","title":"REDCap Custodian Friday Call Demo","text":"Follow steps run code provided vignette(\"friday-call-demo-setup\").","code":""},{"path":"/articles/friday-call-demo.html","id":"premise","dir":"Articles","previous_headings":"","what":"Premise","title":"REDCap Custodian Friday Call Demo","text":"big important project many rows data many rows coming every week, researcher asks build biorepository project biospecimens collected protocol. want anyone transcribe existing data, automatically copy every day. transcription, typos, overtime.","code":""},{"path":"/articles/friday-call-demo.html","id":"get-some-data-from-a-redcap-project","dir":"Articles","previous_headings":"","what":"Get some data from a REDCap project","title":"REDCap Custodian Friday Call Demo","text":"First, load R packages: Next, connect credential database. read credentials REDCap project want read . point, ’s time read portions project data interest . task, want read identifiers collected data can write Biospecimen tracking project customer’s requirements biorepository require us transformations writing. ’s easy dplyr library Now write data target project","code":"library(redcapcustodian) library(DBI) library(tidyverse) library(dotenv) library(lubridate)  load_dot_env(here::here(\"local.env.txt\"))  init_etl(\"friday_call_demo\") file_conn <- DBI::dbConnect(RSQLite::SQLite(), here::here(\"credentials/credentials.db\")) my_username <- \"admin\"  source_credentials <- tbl(file_conn, \"credentials\") %>%   filter(username == my_username) %>%   collect() %>%   filter(str_detect(project_display_name, \"Demo Main\")) %>%   unnest() record_count_to_create <- 50 collection_events <- 5 tubes_per_collection <- 30  fields_to_read <- c(   \"record_id\",   \"redcap_event_name\",   \"sample_collected_date\",   paste0(\"tube_id\", 1:tubes_per_collection),   paste0(\"tube_specimen_type\", 1:tubes_per_collection),   paste0(\"tube_volume\", 1:tubes_per_collection) )  source_project_data <- REDCapR::redcap_read(   redcap_uri = source_credentials$redcap_uri,   token = source_credentials$token,   fields = fields_to_read )  # Validate that data was retrieved and alert regarding issues if (!source_project_data$success) {   warning(\"Data was not successfully read from REDCap\") } # Append the event number to the subject_id to make the record_id needed in the biorepository new_target_project_data <- source_project_data$data %>%   rename(subject_id = record_id) %>%   mutate(record_id = paste0(     subject_id, \"-\",     str_replace(redcap_event_name, \"event_\", \"\") %>% str_replace(., \"_arm_1\", \"\"))) %>%   select(record_id, everything()) %>%   rename(date_draw = sample_collected_date) target_credentials <- tbl(file_conn, \"credentials\") %>%   filter(username == my_username) %>%   collect() %>%   filter(str_detect(project_display_name, \"Demo Biospecimen\")) %>%   unnest()  # Want to know exactly what is getting updated in the target project? Fetch that data then anti-join with the new data set target_fields_to_read <- c(   \"record_id\",   \"redcap_event_name\",   \"sample_collected_date\" )  old_target_project_data <- REDCapR::redcap_read(   redcap_uri = target_credentials$redcap_uri,   token = target_credentials$token,   fields = target_fields_to_read )  if (old_target_project_data$success) {   target_project_data <- new_target_project_data %>%     dplyr::anti_join(old_target_project_data$data) } else {   target_project_data <- new_target_project_data }  # now write that small dataset result <- REDCapR::redcap_write(   ds_to_write = slice_head(target_project_data, prop=0.5),   redcap_uri = target_credentials$redcap_uri,   token = target_credentials$token )  # now log what we did if (result$success) {   log_job_success(jsonlite::toJSON(target_project_data)) } else {   log_job_failure(jsonlite::toJSON(result)) }"},{"path":"/articles/friday-call-demo.html","id":"review-the-logs-of-what-the-job-did","dir":"Articles","previous_headings":"","what":"Review the logs of what the job did","title":"REDCap Custodian Friday Call Demo","text":"automated jobs, ’s important record happened. REDCap Custodian writes logs can review actions later.","code":"# Get the connection to the log database log_con <- get_package_scope_var(\"log_con\")  # Look at the entire log of jobs run tbl(log_con, \"rcc_job_log\") %>%   collect() %>%   view()  # Read the summary of the last 'friday_call_demo' job tbl(log_con, \"rcc_job_log\") %>%   filter(script_name == \"friday_call_demo\") %>%   collect() %>%   arrange(desc(log_date)) %>%   head(n=1) %>%   pull(job_summary_data) %>%   jsonlite::fromJSON() %>%   view()"},{"path":"/articles/randomization-management.html","id":"moving-a-production-project-with-allocated-randomization-records","dir":"Articles","previous_headings":"","what":"Moving a Production project with allocated randomization records","title":"Randomization Management","text":"tools created allow production project randomization turned moved another REDCap project. REDCap doesn’t allow , work done backend database reads write. tables involved REDCap project IDs, randomization IDs, eventIDs, allocations IDs embedded, work requires multiple transformations writing randomization configuration target project. example use randomization management functions copy allocated randomizations shown . script functions calls designed fit workflow:","code":"library(redcapcustodian) library(DBI) library(tidyverse) library(lubridate) library(dotenv)  init_etl(\"copy_allocated_randomization\")  source_conn <- connect_to_redcap_db() # specify a second database connection if the target project is on another host target_conn <- source_conn source_project_id <- 18 target_project_id <- 25  # get and print importable allocations if we need them for reference allocations <- export_allocation_tables_from_project(   conn = source_conn,   project_id_to_export = source_project_id )  target_directory = \"output\" if (!fs::dir_exists(here::here(target_directory))) {   fs::dir_create(here::here(target_directory)) }  walk(c(0,1), write_allocations, allocations, target_directory)  # Configure randomization on the target project target_project_randomization_state <- create_randomization_row(     source_conn = source_conn,     target_conn = target_conn,     source_project_id = source_project_id,     target_project_id = target_project_id )  target_project_allocation_state <- create_allocation_rows(   source_conn = source_conn,   target_conn = target_conn,   source_project_id = source_project_id,   target_project_id = target_project_id )  # Update randomization on the target project target_project_allocation_update <- update_production_allocation_state(   source_conn = source_conn,   target_conn = target_conn,   source_project_id = source_project_id,   target_rid = target_project_randomization_state$rid )  # Enable randomization on the target enable_randomization_on_a_preconfigured_project_in_production(   target_conn = target_conn,   target_project_id = target_project_id )"},{"path":"/articles/randomization-management.html","id":"preparation","dir":"Articles","previous_headings":"Moving a Production project with allocated randomization records","what":"Preparation","title":"Randomization Management","text":"Start production project randomization turned configured, data entered records randomized. source project. Note project ID. Copy/clone source project. Either use Copy Project button REDCap Project Setup, XML export import. new project target project. Note project ID. Turn randomization target project copy/cloning process turned . probably seems strange, ’s needed allow data import randomization field trick REDCap moving project production data “randomization” field assignments allocation table. reconfiguration work needed target project. able move fields forms events needed. said, change names stratification randomization fields. Copy script set values source target project ids. Run copy_allocated_randomization.R script. mirror randomization configuration source project target project. cloned project Copy Project button, script complain configuration data exists. fine. Regardless cloned project, script complain met requirements turn randomization. supposed see warning point.","code":""},{"path":"/articles/randomization-management.html","id":"activation","dir":"Articles","previous_headings":"Moving a Production project with allocated randomization records","what":"Activation","title":"Randomization Management","text":"Take source project offline. changes occurred data source project since cloned , re-export data source project import target project. Immediately move target project production. Immediately re-run copy_allocated_randomization.R script. turn randomization target project. Revoke access source project. done.","code":""},{"path":"/articles/randomization-management.html","id":"limitations","dir":"Articles","previous_headings":"","what":"Limitations","title":"Randomization Management","text":"randomization management tools support DAG group_ids randomization variables. , don’t needed project inspired tools. try use project uses DAGs randomization configuration. tools support changing randomization configuration. might form good foundation , support .","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Philip Chase. Author, maintainer. Laurence James-Woodley. Author. Kyle Chesney. Author. Taryn Stoffs. Contributor. Michael Bentz. Author. Christopher Barnes. Contributor.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Chase P, James-Woodley L, Chesney K, Bentz M (2023). redcapcustodian: Data automation R-centric workflows nod towards REDCap. https://ctsit.github.io/redcapcustodian/, https://github.com/ctsit/redcapcustodian/, https://project-redcap.org.","code":"@Manual{,   title = {redcapcustodian: Data automation for R-centric workflows with a nod towards REDCap},   author = {Philip Chase and Laurence James-Woodley and Kyle Chesney and Michael Bentz},   year = {2023},   note = {https://ctsit.github.io/redcapcustodian/, https://github.com/ctsit/redcapcustodian/, https://project-redcap.org}, }"},{"path":"/index.html","id":"redcap-custodian","dir":"","previous_headings":"","what":"Data automation for R-centric workflows with a nod towards REDCap","title":"Data automation for R-centric workflows with a nod towards REDCap","text":"package simplifies data management activities REDCap systems. provides framework automating data extraction, transformation, loading (ETL) work. supports ETL work within REDCap, REDCap projects, REDCap systems, REDCap database. provides extensible set R functions, Docker image, Rstudio Project template upon REDCap team can build ETL tasks serve REDCap systems customers.","code":""},{"path":"/index.html","id":"operating-environment","dir":"","previous_headings":"","what":"Operating environment","title":"Data automation for R-centric workflows with a nod towards REDCap","text":"redcapcustodian R package can referenced R script needs ETL work REDCap data target. facilitate automation, repository also provides Dockerfile provides R, redcapcustodian package, required packages. Dockerfile build.sh can used build Docker image named redcapcustodian can serve foundation containers serve specific tasks. build upon foundation, repository also provides folder, study_template can copied new folder used starting point Rstudio project, R package, Docker image address needs single study data management project. tools designed simplify development reduce burden automating data reporting recurring data management tasks. automated environment, ETL job system Rscript run via Docker. report RMarkdown file run via Docker. design assumes Docker containers hosted Linux host API access one REDCap systems, mail server, MySQL database, , optionally, REDCap database . sites without container infrastructure, image can instantiated container via cron job documented files study_template/crons/. file folder runs single job. run job, cron script must copied /etc/cron.d/ folder Linux host. build.sh script builds redcapcustodian container upon containers built study template depend.","code":""},{"path":"/index.html","id":"how-to-use-this-project","dir":"","previous_headings":"","what":"How to use this project","title":"Data automation for R-centric workflows with a nod towards REDCap","text":"repository provides three elements designed used together manage data single study data-management project. provides R package, redcapcustodian provides functions facilitate credential management, database connections, data comparison, data synchronization, logging. provides Dockerfile rolls-redcapcustodian package, dependencies several recommended R packages typically needed working REDCap. repository also provides study_template can used starting point repository Docker container house run study’s custom RScript, Rmarkdown, R package. REDCap Custodian package can used custom RScript simply installing loading package RStudio: use Docker container, ’ll need checkout repository git build Dockerfile. Mac Linux computer steps look like : procedure use study template involved, offers reward well. See Writing redcapcustodian Rscripts. might also help look Developer Notes","code":"install.packages(\"devtools\") devtools::install_github(\"ctsit/redcapcustodian\") library(redcapcustodian) git clone git@github.com:ctsit/redcapcustodian.git cd redcapcustodian ./build.sh"},{"path":"/index.html","id":"areas-of-redcap-interest","dir":"","previous_headings":"","what":"Areas of REDCap interest","title":"Data automation for R-centric workflows with a nod towards REDCap","text":"much REDCap Custodian repository package automating workflows, package includes tools specific REDCap. API token management, see Credential Scraping tools procedures moving production projects use randomization, See Randomization Management bulk rights expiration, see function expire_user_project_rights()","code":""},{"path":"/reference/build_etl_job_log_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Builds formatted rcc_job_log data frame from source data — build_etl_job_log_df","title":"Builds formatted rcc_job_log data frame from source data — build_etl_job_log_df","text":"Builds formatted rcc_job_log data frame source data","code":""},{"path":"/reference/build_etl_job_log_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Builds formatted rcc_job_log data frame from source data — build_etl_job_log_df","text":"","code":"build_etl_job_log_df(job_duration, job_summary, level)"},{"path":"/reference/build_etl_job_log_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Builds formatted rcc_job_log data frame from source data — build_etl_job_log_df","text":"job_duration, job duration seconds job_summary, summary job performed level, log level (DEBUG, ERROR, INFO)","code":""},{"path":"/reference/build_etl_job_log_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Builds formatted rcc_job_log data frame from source data — build_etl_job_log_df","text":"df_etl_log_job, df matching rcc_job_log table","code":""},{"path":[]},{"path":"/reference/build_formatted_df_from_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Builds formatted data frame from source data — build_formatted_df_from_result","title":"Builds formatted data frame from source data — build_formatted_df_from_result","text":"Builds formatted data frame source data","code":""},{"path":"/reference/build_formatted_df_from_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Builds formatted data frame from source data — build_formatted_df_from_result","text":"","code":"build_formatted_df_from_result(   result,   database_written,   table_written,   log_level,   pk_col )"},{"path":"/reference/build_formatted_df_from_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Builds formatted data frame from source data — build_formatted_df_from_result","text":"result, df log database_written, database etl wrote table_written, table etl wrote log_level, log level (DEBUG, ERROR, INFO) pk_col, dataframe col use primary_key","code":""},{"path":"/reference/build_formatted_df_from_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Builds formatted data frame from source data — build_formatted_df_from_result","text":"df_etl_log, df matching etl_log table","code":""},{"path":"/reference/build_formatted_df_from_result.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Builds formatted data frame from source data — build_formatted_df_from_result","text":"","code":"if (FALSE) {  build_formatted_df_from_result(    result,    database_written,    table_written,    log_level,    pk_col  ) }"},{"path":"/reference/connect_to_db.html","id":null,"dir":"Reference","previous_headings":"","what":"Connect to db — connect_to_db","title":"Connect to db — connect_to_db","text":"Connect db","code":""},{"path":"/reference/connect_to_db.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Connect to db — connect_to_db","text":"","code":"connect_to_db(drv, prefix = \"\", continue_on_error = FALSE)"},{"path":"/reference/connect_to_db.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Connect to db — connect_to_db","text":"drv, object inherits DBIDriver (e.g. RMariaDB::MariaDB()), existing DBIConnection object (order clone existing connection). prefix, continue_on_error TRUE continue execution error, FALSE quit non interactive sessions error","code":""},{"path":"/reference/connect_to_db.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Connect to db — connect_to_db","text":"S4 object. Run ?dbConnect information","code":""},{"path":"/reference/connect_to_db.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Connect to db — connect_to_db","text":"","code":"if (FALSE) { # connect to db using [prefix]_DB_* environment variables con <- connect_to_db(drv = RMariaDB::MariaDB(), prefix = \"RCC\")  # connect to sqlite db con <- connect_to_db(drv = RSQLite::SQLite()) }"},{"path":"/reference/connect_to_log_db.html","id":null,"dir":"Reference","previous_headings":"","what":"Connect to the log db — connect_to_log_db","title":"Connect to the log db — connect_to_log_db","text":"Connect log db","code":""},{"path":"/reference/connect_to_log_db.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Connect to the log db — connect_to_log_db","text":"","code":"connect_to_log_db(drv, continue_on_error = FALSE)"},{"path":"/reference/connect_to_log_db.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Connect to the log db — connect_to_log_db","text":"drv, object inherits DBIDriver (e.g. RMariaDB::MariaDB()), existing DBIConnection object (order clone existing connection). continue_on_error TRUE continue execution error, FALSE quit non interactive sessions error","code":""},{"path":"/reference/connect_to_log_db.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Connect to the log db — connect_to_log_db","text":"S4 object. Run ?dbConnect information","code":""},{"path":"/reference/connect_to_log_db.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Connect to the log db — connect_to_log_db","text":"","code":"if (FALSE) { # connect to log db using LOG_DB_* environment variables con <- connect_to_log_db()  # connect to sqlite log db con <- connect_to_log_db(drv = RSQLite::SQLite()) }"},{"path":"/reference/connect_to_redcap_db.html","id":null,"dir":"Reference","previous_headings":"","what":"Connect to the Primary REDCap MySQL Database\nAssigns package-scoped conn — connect_to_redcap_db","title":"Connect to the Primary REDCap MySQL Database\nAssigns package-scoped conn — connect_to_redcap_db","text":"Connect Primary REDCap MySQL Database Assigns package-scoped conn","code":""},{"path":"/reference/connect_to_redcap_db.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Connect to the Primary REDCap MySQL Database\nAssigns package-scoped conn — connect_to_redcap_db","text":"","code":"connect_to_redcap_db()"},{"path":"/reference/connect_to_redcap_db.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Connect to the Primary REDCap MySQL Database\nAssigns package-scoped conn — connect_to_redcap_db","text":"S4 object. Run ?dbConnect information","code":""},{"path":"/reference/connect_to_redcap_db.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Connect to the Primary REDCap MySQL Database\nAssigns package-scoped conn — connect_to_redcap_db","text":"","code":"if (FALSE) { conn <- connect_to_redcap_db() }"},{"path":"/reference/convert_schema_to_sqlite.html","id":null,"dir":"Reference","previous_headings":"","what":"Converts a MySQL schema file to a sqlite schema.\nFacilitates easier creation of in-memory (i.e. sqlite) tables. — convert_schema_to_sqlite","title":"Converts a MySQL schema file to a sqlite schema.\nFacilitates easier creation of in-memory (i.e. sqlite) tables. — convert_schema_to_sqlite","text":"Converts MySQL schema file sqlite schema. Facilitates easier creation -memory (.e. sqlite) tables.","code":""},{"path":"/reference/convert_schema_to_sqlite.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts a MySQL schema file to a sqlite schema.\nFacilitates easier creation of in-memory (i.e. sqlite) tables. — convert_schema_to_sqlite","text":"","code":"convert_schema_to_sqlite(schema_file_path)"},{"path":"/reference/convert_schema_to_sqlite.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converts a MySQL schema file to a sqlite schema.\nFacilitates easier creation of in-memory (i.e. sqlite) tables. — convert_schema_to_sqlite","text":"schema_file_path, path schema file convert","code":""},{"path":"/reference/convert_schema_to_sqlite.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converts a MySQL schema file to a sqlite schema.\nFacilitates easier creation of in-memory (i.e. sqlite) tables. — convert_schema_to_sqlite","text":"translated schema character string","code":""},{"path":"/reference/convert_schema_to_sqlite.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Converts a MySQL schema file to a sqlite schema.\nFacilitates easier creation of in-memory (i.e. sqlite) tables. — convert_schema_to_sqlite","text":"","code":"if (FALSE) { mem_conn <- DBI::dbConnect(RSQLite::SQLite(), dbname = \":memory:\") translated_schema <- convert_schema_to_sqlite(\"~/documents/my_cool_schema.sql\") DBI::dbSendQuery(mem_conn, schema) }"},{"path":"/reference/create_allocation_rows.html","id":null,"dir":"Reference","previous_headings":"","what":"create_allocation_rows — create_allocation_rows","title":"create_allocation_rows — create_allocation_rows","text":"Create rows redcap_randomization_allocation table mirror another project.","code":""},{"path":"/reference/create_allocation_rows.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"create_allocation_rows — create_allocation_rows","text":"","code":"create_allocation_rows(   source_conn,   target_conn,   source_project_id,   target_project_id )"},{"path":"/reference/create_allocation_rows.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"create_allocation_rows — create_allocation_rows","text":"source_conn - DBI connection object pointing REDCap database houses source project. target_conn - DBI connection object pointing REDCap database houses target project. source_project_id - project ID REDCap project contains randomization cloned. target_project_id - project ID REDCap project receive mirrored randomization data.","code":""},{"path":"/reference/create_allocation_rows.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"create_allocation_rows — create_allocation_rows","text":"- dataframe containing current allocation rows   target project.","code":""},{"path":"/reference/create_allocation_rows.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"create_allocation_rows — create_allocation_rows","text":"","code":"if (FALSE) { target_project_allocation_state <- create_allocation_rows(   source_conn = source_conn,   target_conn = target_conn,   source_project_id = source_project_id,   target_project_id = target_project_id ) }"},{"path":"/reference/create_randomization_row.html","id":null,"dir":"Reference","previous_headings":"","what":"create_randomization_row — create_randomization_row","title":"create_randomization_row — create_randomization_row","text":"Create single row redcap_randomization table mirrors another project.","code":""},{"path":"/reference/create_randomization_row.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"create_randomization_row — create_randomization_row","text":"","code":"create_randomization_row(   source_conn,   target_conn,   source_project_id,   target_project_id )"},{"path":"/reference/create_randomization_row.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"create_randomization_row — create_randomization_row","text":"source_conn - DBI connection object pointing REDCap database houses source project. target_conn - DBI connection object pointing REDCap database houses target project. source_project_id - project ID REDCap project contains randomization cloned. target_project_id - project ID REDCap project receive mirrored randomization data.","code":""},{"path":"/reference/create_randomization_row.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"create_randomization_row — create_randomization_row","text":"- dataframe containing current randomization row   target project.","code":""},{"path":"/reference/create_randomization_row.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"create_randomization_row — create_randomization_row","text":"","code":"if (FALSE) { target_project_randomization_state <- create_randomization_row(   source_conn = source_conn,   target_conn = target_conn,   source_project_id = source_project_id,   target_project_id = target_project_id ) }"},{"path":"/reference/create_test_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a test table from package schema and data files — create_test_table","title":"Create a test table from package schema and data files — create_test_table","text":"Creates tables files inst/testdata match patterns <table_name>_schema.sql <table_name>.csv","code":""},{"path":"/reference/create_test_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a test table from package schema and data files — create_test_table","text":"","code":"create_test_table(conn, table_name, data_file = NA_character_, empty = F)"},{"path":"/reference/create_test_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a test table from package schema and data files — create_test_table","text":"conn DBI Connection object table_name name table used testing data_file name file alternative contents `table_name` empty boolean request table created empty","code":""},{"path":"/reference/create_test_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a test table from package schema and data files — create_test_table","text":"NA","code":""},{"path":"/reference/create_test_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a test table from package schema and data files — create_test_table","text":"","code":"if (FALSE) { conn <- dbConnect(RSQLite::SQLite(), dbname = \":memory:\") create_test_table(conn, \"redcap_user_information\")  }"},{"path":"/reference/create_test_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"A wrapper around create_test_table to create all tables, or a specified subset of them — create_test_tables","title":"A wrapper around create_test_table to create all tables, or a specified subset of them — create_test_tables","text":"wrapper around create_test_table create tables, specified subset ","code":""},{"path":"/reference/create_test_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A wrapper around create_test_table to create all tables, or a specified subset of them — create_test_tables","text":"","code":"create_test_tables(conn, table_names = c())"},{"path":"/reference/create_test_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A wrapper around create_test_table to create all tables, or a specified subset of them — create_test_tables","text":"conn DBI Connection object table_names character list names tables wish create, nothing provided, result get_test_table_names used create test tables","code":""},{"path":"/reference/create_test_tables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A wrapper around create_test_table to create all tables, or a specified subset of them — create_test_tables","text":"NA","code":""},{"path":"/reference/create_test_tables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A wrapper around create_test_table to create all tables, or a specified subset of them — create_test_tables","text":"","code":"if (FALSE) { conn <- dbConnect(RSQLite::SQLite(), dbname = \":memory:\") create_test_tables(conn) # create all test tables  }"},{"path":"/reference/dataset_diff.html","id":null,"dir":"Reference","previous_headings":"","what":"dataset_diff — dataset_diff","title":"dataset_diff — dataset_diff","text":"returns differences source target data list dataframes records updated, inserted, deleted, update target facts source.","code":""},{"path":"/reference/dataset_diff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dataset_diff — dataset_diff","text":"","code":"dataset_diff(source, source_pk, target, target_pk, insert = T, delete = T)"},{"path":"/reference/dataset_diff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"dataset_diff — dataset_diff","text":"source - dataframe content needs reflected target source_pk - primary key source target - data frame needs reflect source target_pk - primary key target insert - compute return insert records delete - compute return delete records","code":""},{"path":"/reference/dataset_diff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"dataset_diff — dataset_diff","text":"list dataframes update_records - column redcap user_ids / institutional IDs insert_records - column authoritative email address user_id NA insert NA delete_records ... - Additional columns allowed return data frame NA delete NA","code":""},{"path":"/reference/dataset_diff.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"dataset_diff — dataset_diff","text":"goal allow intelligent one-way synchronization source target datasets using database CRUD operations. two assumptions source target: 1. Columns source subset columns target.   2. target_pk appear source.","code":""},{"path":"/reference/dataset_diff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"dataset_diff — dataset_diff","text":"","code":"if (FALSE) { dataset_diff(source = dataset_diff_test_user_data$source,   source_pk = \"username\",   target = dataset_diff_test_user_data$target,   target_pk = \"ui_id\" ) }"},{"path":"/reference/dataset_diff_test_bar_bang.html","id":null,"dir":"Reference","previous_headings":"","what":"dataset_diff_test_bar_bang — dataset_diff_test_bar_bang","title":"dataset_diff_test_bar_bang — dataset_diff_test_bar_bang","text":"list test inputs outputs dataset_diff","code":""},{"path":"/reference/dataset_diff_test_bar_bang.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dataset_diff_test_bar_bang — dataset_diff_test_bar_bang","text":"","code":"dataset_diff_test_bar_bang"},{"path":"/reference/dataset_diff_test_bar_bang.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"dataset_diff_test_bar_bang — dataset_diff_test_bar_bang","text":"list 5 variables: source tibble source data source_pk character primary key source data target tibble target data target_pk character primary key target data result list dataset_diff output","code":""},{"path":"/reference/dataset_diff_test_bar_bang.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"dataset_diff_test_bar_bang — dataset_diff_test_bar_bang","text":"DETAILS","code":""},{"path":"/reference/dataset_diff_test_user_data.html","id":null,"dir":"Reference","previous_headings":"","what":"dataset_diff_test_user_data — dataset_diff_test_user_data","title":"dataset_diff_test_user_data — dataset_diff_test_user_data","text":"list test inputs outputs dataset_diff","code":""},{"path":"/reference/dataset_diff_test_user_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dataset_diff_test_user_data — dataset_diff_test_user_data","text":"","code":"dataset_diff_test_user_data"},{"path":"/reference/dataset_diff_test_user_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"dataset_diff_test_user_data — dataset_diff_test_user_data","text":"list 5 variables: source tibble source data source_pk character primary key source data target tibble target data target_pk character primary key target data result list dataset_diff output","code":""},{"path":"/reference/dataset_diff_test_user_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"dataset_diff_test_user_data — dataset_diff_test_user_data","text":"DETAILS","code":""},{"path":"/reference/disable_non_interactive_quit.html","id":null,"dir":"Reference","previous_headings":"","what":"Prevent quit_non_interactive_run from quitting.\nThis is not meant to be used outside of tests. See test-write.R for an example. — disable_non_interactive_quit","title":"Prevent quit_non_interactive_run from quitting.\nThis is not meant to be used outside of tests. See test-write.R for an example. — disable_non_interactive_quit","text":"Prevent quit_non_interactive_run quitting. meant used outside tests. See test-write.R example.","code":""},{"path":"/reference/disable_non_interactive_quit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prevent quit_non_interactive_run from quitting.\nThis is not meant to be used outside of tests. See test-write.R for an example. — disable_non_interactive_quit","text":"","code":"disable_non_interactive_quit()"},{"path":"/reference/disable_non_interactive_quit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prevent quit_non_interactive_run from quitting.\nThis is not meant to be used outside of tests. See test-write.R for an example. — disable_non_interactive_quit","text":"","code":"if (FALSE) {  disable_non_interactive_quit() }"},{"path":"/reference/enable_randomization_on_a_preconfigured_project_in_production.html","id":null,"dir":"Reference","previous_headings":"","what":"enable_randomization_on_a_preconfigured_project_in_production — enable_randomization_on_a_preconfigured_project_in_production","title":"enable_randomization_on_a_preconfigured_project_in_production — enable_randomization_on_a_preconfigured_project_in_production","text":"Turn randomization target project already    moved production randomization configured.","code":""},{"path":"/reference/enable_randomization_on_a_preconfigured_project_in_production.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"enable_randomization_on_a_preconfigured_project_in_production — enable_randomization_on_a_preconfigured_project_in_production","text":"","code":"enable_randomization_on_a_preconfigured_project_in_production(   target_conn,   target_project_id )"},{"path":"/reference/enable_randomization_on_a_preconfigured_project_in_production.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"enable_randomization_on_a_preconfigured_project_in_production — enable_randomization_on_a_preconfigured_project_in_production","text":"target_conn - DBI connection object pointing REDCap database houses target project. target_project_id - project ID REDCap project receive mirrored randomization data.","code":""},{"path":"/reference/enable_randomization_on_a_preconfigured_project_in_production.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"enable_randomization_on_a_preconfigured_project_in_production — enable_randomization_on_a_preconfigured_project_in_production","text":"logical indicating success failure operation","code":""},{"path":"/reference/enable_randomization_on_a_preconfigured_project_in_production.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"enable_randomization_on_a_preconfigured_project_in_production — enable_randomization_on_a_preconfigured_project_in_production","text":"","code":"if (FALSE) { enable_randomization_on_a_preconfigured_project_in_production(   target_conn = target_conn,   target_project_id = target_project_id ) }"},{"path":"/reference/expire_user_project_rights.html","id":null,"dir":"Reference","previous_headings":"","what":"Expire user rights to REDCap projects — expire_user_project_rights","title":"Expire user rights to REDCap projects — expire_user_project_rights","text":"Expire user rights one REDCap projects based list users expire users exclude expiration","code":""},{"path":"/reference/expire_user_project_rights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expire user rights to REDCap projects — expire_user_project_rights","text":"","code":"expire_user_project_rights(   conn,   project_ids,   usernames = NULL,   all_users_except = NULL,   expiration_date = as.Date(NA) )"},{"path":"/reference/expire_user_project_rights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expire user rights to REDCap projects — expire_user_project_rights","text":"conn, DBI Connection object REDCap database project_ids, vector project IDs whose users need expiration usernames, vector usernames expire across vector project IDs all_users_except, vector usernames excluded expiration expiration_date, expiration date applied users. Defaults today.","code":""},{"path":"/reference/expire_user_project_rights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expire user rights to REDCap projects — expire_user_project_rights","text":"list update count data written updates - number records revised data - dataframe changes applied redcap_user_rights","code":""},{"path":"/reference/expire_user_project_rights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expire user rights to REDCap projects — expire_user_project_rights","text":"","code":"conn <- DBI::dbConnect(RSQLite::SQLite(), dbname = \":memory:\")  DBI::dbCreateTable(   conn,   name = \"redcap_user_rights\",   fields = user_rights_test_data$redcap_user_rights ) DBI::dbAppendTable(   conn,   name = \"redcap_user_rights\",   value = user_rights_test_data$redcap_user_rights ) #> [1] 27  usernames <- c(\"bob\", \"dan\")  expire_user_project_rights(   conn = conn,   project_ids = c(34),   usernames = usernames ) #> Error in check_dbplyr(): The package \"dbplyr\" is required to communicate with database backends."},{"path":"/reference/export_allocation_tables_from_project.html","id":null,"dir":"Reference","previous_headings":"","what":"export_allocation_tables_from_project — export_allocation_tables_from_project","title":"export_allocation_tables_from_project — export_allocation_tables_from_project","text":"Export randomization allocation data project REDCap   randomization tables form reflects allocation tables   REDCap requests import","code":""},{"path":"/reference/export_allocation_tables_from_project.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"export_allocation_tables_from_project — export_allocation_tables_from_project","text":"","code":"export_allocation_tables_from_project(conn, project_id_to_export)"},{"path":"/reference/export_allocation_tables_from_project.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"export_allocation_tables_from_project — export_allocation_tables_from_project","text":"conn - DBI connection object pointing REDCap database houses project interest project_id_to_export - project ID REDCap project contains randomization exported.","code":""},{"path":"/reference/export_allocation_tables_from_project.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"export_allocation_tables_from_project — export_allocation_tables_from_project","text":"dataframe shape REDCap randomization table CSVs","code":""},{"path":"/reference/export_allocation_tables_from_project.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"export_allocation_tables_from_project — export_allocation_tables_from_project","text":"","code":"if (FALSE) { allocations <- export_allocation_tables_from_project(   conn = source_conn,   project_id_to_export = source_project_id ) }"},{"path":"/reference/get_bad_emails_from_individual_emails.html","id":null,"dir":"Reference","previous_headings":"","what":"Scrape an inbox for bad email addresses in bounce messages — get_bad_emails_from_individual_emails","title":"Scrape an inbox for bad email addresses in bounce messages — get_bad_emails_from_individual_emails","text":"Connect imap mailbox, identify bad email addresses referenced bounce messages sent `messages_since_date`, extract data emails.","code":""},{"path":"/reference/get_bad_emails_from_individual_emails.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scrape an inbox for bad email addresses in bounce messages — get_bad_emails_from_individual_emails","text":"","code":"get_bad_emails_from_individual_emails(   username,   password,   url = \"imaps://outlook.office365.com\",   messages_since_date )"},{"path":"/reference/get_bad_emails_from_individual_emails.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scrape an inbox for bad email addresses in bounce messages — get_bad_emails_from_individual_emails","text":"username username IMAP mailbox password password IMAP mailbox url IMAP URL host houses mailbox messages_since_date sent date oldest message inspected","code":""},{"path":"/reference/get_bad_emails_from_individual_emails.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scrape an inbox for bad email addresses in bounce messages — get_bad_emails_from_individual_emails","text":"dataframe bounced email addresses emailcharacter email address bounced","code":""},{"path":"/reference/get_bad_emails_from_individual_emails.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scrape an inbox for bad email addresses in bounce messages — get_bad_emails_from_individual_emails","text":"","code":"if (FALSE) { get_bad_emails_from_individual_emails(   username = \"jdoe\",   password = \"jane_does_password\",   url =\"imaps://outlook.office365.com\",   messages_since_date = as.Date(\"2022-01-01\", format = \"%Y-%m-%d\")   ) }"},{"path":"/reference/get_bad_emails_from_listserv_digest.html","id":null,"dir":"Reference","previous_headings":"","what":"Enumerate bad email addresses described in LISTSERV email digests — get_bad_emails_from_listserv_digest","title":"Enumerate bad email addresses described in LISTSERV email digests — get_bad_emails_from_listserv_digest","text":"Connect imap mailbox, identify LISTSERV digest emails sent `messages_since_date`, extract bounced email addresses digest messages.","code":""},{"path":"/reference/get_bad_emails_from_listserv_digest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enumerate bad email addresses described in LISTSERV email digests — get_bad_emails_from_listserv_digest","text":"","code":"get_bad_emails_from_listserv_digest(   username,   password,   url = \"imaps://outlook.office365.com\",   messages_since_date )"},{"path":"/reference/get_bad_emails_from_listserv_digest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enumerate bad email addresses described in LISTSERV email digests — get_bad_emails_from_listserv_digest","text":"username username IMAP mailbox password password IMAP mailbox url IMAP URL host houses mailbox messages_since_date sent date oldest message inspected","code":""},{"path":"/reference/get_bad_emails_from_listserv_digest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Enumerate bad email addresses described in LISTSERV email digests — get_bad_emails_from_listserv_digest","text":"dataframe bad email addresses email - column bad email address","code":""},{"path":"/reference/get_bad_emails_from_listserv_digest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Enumerate bad email addresses described in LISTSERV email digests — get_bad_emails_from_listserv_digest","text":"","code":"if (FALSE) { get_bad_emails_from_listserv_digest(   username = \"jdoe\",   password = \"jane_does_password\",   url =\"imaps://outlook.office365.com\",   messages_since_date = as.Date(\"2022-01-01\", format = \"%Y-%m-%d\")   ) }"},{"path":"/reference/get_bad_emails_from_listserv_digest_test_output.html","id":null,"dir":"Reference","previous_headings":"","what":"get_bad_emails_from_listserv_digest_test_output — get_bad_emails_from_listserv_digest_test_output","title":"get_bad_emails_from_listserv_digest_test_output — get_bad_emails_from_listserv_digest_test_output","text":"example output get_bad_emails_from_listserv_digest aligns related tests","code":""},{"path":"/reference/get_bad_emails_from_listserv_digest_test_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get_bad_emails_from_listserv_digest_test_output — get_bad_emails_from_listserv_digest_test_output","text":"","code":"get_bad_emails_from_listserv_digest_test_output"},{"path":"/reference/get_bad_emails_from_listserv_digest_test_output.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"get_bad_emails_from_listserv_digest_test_output — get_bad_emails_from_listserv_digest_test_output","text":"data frame 7 rows 1 variables: email character bad email address found querying listserv error digests","code":""},{"path":"/reference/get_bad_emails_from_listserv_digest_test_output.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"get_bad_emails_from_listserv_digest_test_output — get_bad_emails_from_listserv_digest_test_output","text":"DETAILS","code":""},{"path":"/reference/get_current_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetches the current time in system time zone — get_current_time","title":"Fetches the current time in system time zone — get_current_time","text":"Fetches current time system time zone","code":""},{"path":"/reference/get_current_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetches the current time in system time zone — get_current_time","text":"","code":"get_current_time()"},{"path":"/reference/get_current_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetches the current time in system time zone — get_current_time","text":"duration object representing current time","code":""},{"path":"/reference/get_current_time.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fetches the current time in system time zone — get_current_time","text":"","code":"if (FALSE) { get_current_time() }"},{"path":"/reference/get_institutional_person_data.html","id":null,"dir":"Reference","previous_headings":"","what":"A template function for fetching authoritative email address data\nand other institutional data — get_institutional_person_data","title":"A template function for fetching authoritative email address data\nand other institutional data — get_institutional_person_data","text":"template function fetching authoritative email address data institutional data","code":""},{"path":"/reference/get_institutional_person_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A template function for fetching authoritative email address data\nand other institutional data — get_institutional_person_data","text":"","code":"get_institutional_person_data(user_ids = c(NA_character_))"},{"path":"/reference/get_institutional_person_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A template function for fetching authoritative email address data\nand other institutional data — get_institutional_person_data","text":"user_ids optional vector REDCap user IDs used query institutional data","code":""},{"path":"/reference/get_institutional_person_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A template function for fetching authoritative email address data\nand other institutional data — get_institutional_person_data","text":"Dataframe user_id - column redcap user_ids / institutional IDs email - column authoritative email address user_id ... - Additional columns allowed return data frame","code":""},{"path":"/reference/get_institutional_person_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A template function for fetching authoritative email address data\nand other institutional data — get_institutional_person_data","text":"","code":"redcap_users <- c(\"jane_doe\", \"john_q_public\") get_institutional_person_data(user_ids = redcap_users) #> # A tibble: 2 × 2 #>   user_id       email                     #>   <chr>         <chr>                     #> 1 jane_doe      jane_doe@example.org      #> 2 john_q_public john_q_public@example.org"},{"path":"/reference/get_job_duration.html","id":null,"dir":"Reference","previous_headings":"","what":"Provide the exact length of the time span between start time and end time — get_job_duration","title":"Provide the exact length of the time span between start time and end time — get_job_duration","text":"Provide exact length time span start time end time","code":""},{"path":"/reference/get_job_duration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Provide the exact length of the time span between start time and end time — get_job_duration","text":"","code":"get_job_duration(start_time, end_time)"},{"path":"/reference/get_job_duration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Provide the exact length of the time span between start time and end time — get_job_duration","text":"start_time, lubridate::duration object representing start time end_time, lubridate::duration object representing end time","code":""},{"path":"/reference/get_job_duration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Provide the exact length of the time span between start time and end time — get_job_duration","text":"exact length time span start time end time","code":""},{"path":[]},{"path":"/reference/get_package_scope_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the value from the redcapcustodian.env environment — get_package_scope_var","title":"Get the value from the redcapcustodian.env environment — get_package_scope_var","text":"Get value redcapcustodian.env environment","code":""},{"path":"/reference/get_package_scope_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the value from the redcapcustodian.env environment — get_package_scope_var","text":"","code":"get_package_scope_var(key)"},{"path":"/reference/get_package_scope_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the value from the redcapcustodian.env environment — get_package_scope_var","text":"key identifying string lookup","code":""},{"path":"/reference/get_package_scope_var.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the value from the redcapcustodian.env environment — get_package_scope_var","text":"","code":"if (FALSE) {   get_package_scope_var(\"hello\") }"},{"path":"/reference/get_redcap_db_connection.html","id":null,"dir":"Reference","previous_headings":"","what":"Get connection to the primary REDCap database — get_redcap_db_connection","title":"Get connection to the primary REDCap database — get_redcap_db_connection","text":"Get connection primary REDCap database","code":""},{"path":"/reference/get_redcap_db_connection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get connection to the primary REDCap database — get_redcap_db_connection","text":"","code":"get_redcap_db_connection()"},{"path":"/reference/get_redcap_db_connection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get connection to the primary REDCap database — get_redcap_db_connection","text":"existing connection object REDCap database","code":""},{"path":"/reference/get_redcap_db_connection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get connection to the primary REDCap database — get_redcap_db_connection","text":"","code":"if (FALSE) { conn <- get_redcap_db_connection() }"},{"path":"/reference/get_redcap_email_revisions.html","id":null,"dir":"Reference","previous_headings":"","what":"Get redcap user email revisions — get_redcap_email_revisions","title":"Get redcap user email revisions — get_redcap_email_revisions","text":"Get redcap user email revisions","code":""},{"path":"/reference/get_redcap_email_revisions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get redcap user email revisions — get_redcap_email_revisions","text":"","code":"get_redcap_email_revisions(bad_redcap_user_emails, person)"},{"path":"/reference/get_redcap_email_revisions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get redcap user email revisions — get_redcap_email_revisions","text":"bad_redcap_user_emails bad redcap user email data person institutional person data keyed user_id","code":""},{"path":"/reference/get_redcap_email_revisions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get redcap user email revisions — get_redcap_email_revisions","text":"dataframe columns: ui_id - ui_id associated user REDCap's redcap_user_information table username - REDCap username email_field_name - name column containing email address corrected_email - corrected email address placed column email_field_name","code":""},{"path":"/reference/get_redcap_email_revisions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get redcap user email revisions — get_redcap_email_revisions","text":"","code":"if (FALSE) { conn <- dbConnect(RSQLite::SQLite(), dbname = \":memory:\") bad_emails <- get_bad_redcap_user_emails() persons <- get_institutional_person_data(conn) email_revisions <- get_redcap_email_revisions(bad_emails, persons) }"},{"path":"/reference/get_redcap_email_revisions_test_data.html","id":null,"dir":"Reference","previous_headings":"","what":"get_redcap_email_revisions_test_data — get_redcap_email_revisions_test_data","title":"get_redcap_email_revisions_test_data — get_redcap_email_revisions_test_data","text":"list test inputs outputs get_redcap_email_revisions","code":""},{"path":"/reference/get_redcap_email_revisions_test_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get_redcap_email_revisions_test_data — get_redcap_email_revisions_test_data","text":"","code":"get_redcap_email_revisions_test_data"},{"path":"/reference/get_redcap_email_revisions_test_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"get_redcap_email_revisions_test_data — get_redcap_email_revisions_test_data","text":"list 3 tibbles: bad_redcap_user_emails tibble bad email address redcap usernames person tibble corrected email addresses corresponding usernames output tibble output get_redcap_email_revisions","code":""},{"path":"/reference/get_redcap_email_revisions_test_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"get_redcap_email_revisions_test_data — get_redcap_email_revisions_test_data","text":"DETAILS","code":""},{"path":"/reference/get_redcap_emails.html","id":null,"dir":"Reference","previous_headings":"","what":"Get all user emails in redcap_user_information as tall data — get_redcap_emails","title":"Get all user emails in redcap_user_information as tall data — get_redcap_emails","text":"Get user emails redcap_user_information tall data","code":""},{"path":"/reference/get_redcap_emails.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get all user emails in redcap_user_information as tall data — get_redcap_emails","text":"","code":"get_redcap_emails(conn)"},{"path":"/reference/get_redcap_emails.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get all user emails in redcap_user_information as tall data — get_redcap_emails","text":"conn DBI Connection object","code":""},{"path":"/reference/get_redcap_emails.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get all user emails in redcap_user_information as tall data — get_redcap_emails","text":"list 2 dataframes: wide, relevant email columns redcap_user_information tall, wide data pivoted include email_field_name email columns","code":""},{"path":"/reference/get_redcap_emails.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get all user emails in redcap_user_information as tall data — get_redcap_emails","text":"","code":"if (FALSE) { conn <- dbConnect(RSQLite::SQLite(), dbname = \":memory:\") create_test_table(conn, \"redcap_user_information\") get_redcap_emails(conn) }"},{"path":"/reference/get_redcap_emails_test_data.html","id":null,"dir":"Reference","previous_headings":"","what":"get_redcap_emails_test_data — get_redcap_emails_test_data","title":"get_redcap_emails_test_data — get_redcap_emails_test_data","text":"test data mock get_redcap_emails","code":""},{"path":"/reference/get_redcap_emails_test_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get_redcap_emails_test_data — get_redcap_emails_test_data","text":"","code":"get_redcap_emails_test_data"},{"path":"/reference/get_redcap_emails_test_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"get_redcap_emails_test_data — get_redcap_emails_test_data","text":"object class list length 2.","code":""},{"path":"/reference/get_redcap_emails_test_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"get_redcap_emails_test_data — get_redcap_emails_test_data","text":"list 2 dataframes: wide, relevant email columns redcap_user_information tall, wide data pivoted include email_field_name email columns","code":""},{"path":"/reference/get_redcap_emails_test_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"get_redcap_emails_test_data — get_redcap_emails_test_data","text":"DETAILS","code":""},{"path":"/reference/get_script_name.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetches the package-scoped value of script_name — get_script_name","title":"Fetches the package-scoped value of script_name — get_script_name","text":"Fetches package-scoped value script_name","code":""},{"path":"/reference/get_script_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetches the package-scoped value of script_name — get_script_name","text":"","code":"get_script_name()"},{"path":"/reference/get_script_run_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetches the package-scoped value of script_run_time — get_script_run_time","title":"Fetches the package-scoped value of script_run_time — get_script_run_time","text":"Fetches package-scoped value script_run_time","code":""},{"path":"/reference/get_script_run_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetches the package-scoped value of script_run_time — get_script_run_time","text":"","code":"get_script_run_time()"},{"path":"/reference/get_script_run_time.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fetches the package-scoped value of script_run_time — get_script_run_time","text":"","code":"get_script_run_time() #> NULL"},{"path":"/reference/get_test_table_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Provides a list of table names which have schema and data files as part of the package — get_test_table_names","title":"Provides a list of table names which have schema and data files as part of the package — get_test_table_names","text":"Provides list table names schema data files part package","code":""},{"path":"/reference/get_test_table_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Provides a list of table names which have schema and data files as part of the package — get_test_table_names","text":"","code":"get_test_table_names()"},{"path":"/reference/get_test_table_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Provides a list of table names which have schema and data files as part of the package — get_test_table_names","text":"list table names schema data files part package","code":""},{"path":"/reference/get_test_table_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Provides a list of table names which have schema and data files as part of the package — get_test_table_names","text":"","code":"get_test_table_names() #> [1] \"redcap_projects\"         \"redcap_user_information\""},{"path":"/reference/init_etl.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize all etl dependencies — init_etl","title":"Initialize all etl dependencies — init_etl","text":"Initialize etl dependencies","code":""},{"path":"/reference/init_etl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize all etl dependencies — init_etl","text":"","code":"init_etl(   script_name = \"\",   fake_runtime = NULL,   log_db_drv = RMariaDB::MariaDB() )"},{"path":"/reference/init_etl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize all etl dependencies — init_etl","text":"script_name name passed set_script_name fake_runtime optional asserted script run time passed set_script_run_time, defaults time function called log_db_drv, object inherits DBIDriver (e.g. RMariaDB::MariaDB()), existing DBIConnection object (order clone existing connection).","code":""},{"path":"/reference/init_etl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize all etl dependencies — init_etl","text":"","code":"if (FALSE) {   init_etl(\"name_of_file\") }"},{"path":"/reference/init_log_con.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize the connection to the log db and set redcapcustodian.env$log_con — init_log_con","title":"Initialize the connection to the log db and set redcapcustodian.env$log_con — init_log_con","text":"Initialize connection log db set redcapcustodian.env$log_con","code":""},{"path":"/reference/init_log_con.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize the connection to the log db and set redcapcustodian.env$log_con — init_log_con","text":"","code":"init_log_con(drv = RMariaDB::MariaDB())"},{"path":"/reference/init_log_con.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize the connection to the log db and set redcapcustodian.env$log_con — init_log_con","text":"drv, object inherits DBIDriver (e.g. RMariaDB::MariaDB()), existing DBIConnection object (order clone existing connection).","code":""},{"path":"/reference/init_log_con.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize the connection to the log db and set redcapcustodian.env$log_con — init_log_con","text":"","code":"if (FALSE) {  # use a sqlite db instead  init_log_con(drv = RSQLite::SQLite()) }"},{"path":"/reference/is_db_con.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if the provided connection is a DBI connection object — is_db_con","title":"Check if the provided connection is a DBI connection object — is_db_con","text":"Check provided connection DBI connection object","code":""},{"path":"/reference/is_db_con.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if the provided connection is a DBI connection object — is_db_con","text":"","code":"is_db_con(con)"},{"path":"/reference/is_db_con.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if the provided connection is a DBI connection object — is_db_con","text":"con DBI connection","code":""},{"path":"/reference/is_db_con.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if the provided connection is a DBI connection object — is_db_con","text":"result test","code":""},{"path":"/reference/is_db_con.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if the provided connection is a DBI connection object — is_db_con","text":"","code":"if (FALSE) {  conn = connect_to_local_db()  is_db_con(    con = conn  ) }"},{"path":"/reference/is_on_ci.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if ","title":"Check if ","text":"Check \"CI\" environment variable set TRUE","code":""},{"path":"/reference/is_on_ci.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if ","text":"","code":"is_on_ci()"},{"path":"/reference/is_on_ci.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if ","text":"TRUE/FALSE","code":""},{"path":"/reference/is_on_ci.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if ","text":"","code":"if (FALSE) {   is_on_ci() }"},{"path":"/reference/log_job_debug.html","id":null,"dir":"Reference","previous_headings":"","what":"Log a job debug entry — log_job_debug","title":"Log a job debug entry — log_job_debug","text":"Log job debug entry","code":""},{"path":"/reference/log_job_debug.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log a job debug entry — log_job_debug","text":"","code":"log_job_debug(summary)"},{"path":"/reference/log_job_debug.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log a job debug entry — log_job_debug","text":"summary, job summary","code":""},{"path":"/reference/log_job_debug.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log a job debug entry — log_job_debug","text":"","code":"if (FALSE) {  log_job_debug(    summary = \"Job debug step\"  ) }"},{"path":"/reference/log_job_failure.html","id":null,"dir":"Reference","previous_headings":"","what":"Log a failed job run — log_job_failure","title":"Log a failed job run — log_job_failure","text":"Log failed job run","code":""},{"path":"/reference/log_job_failure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log a failed job run — log_job_failure","text":"","code":"log_job_failure(summary)"},{"path":"/reference/log_job_failure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log a failed job run — log_job_failure","text":"summary, job summary","code":""},{"path":"/reference/log_job_failure.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log a failed job run — log_job_failure","text":"","code":"if (FALSE) {  log_job_failure(    summary = \"Job failed\"  ) }"},{"path":"/reference/log_job_success.html","id":null,"dir":"Reference","previous_headings":"","what":"Log a successful job run — log_job_success","title":"Log a successful job run — log_job_success","text":"Log successful job run","code":""},{"path":"/reference/log_job_success.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log a successful job run — log_job_success","text":"","code":"log_job_success(summary)"},{"path":"/reference/log_job_success.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log a successful job run — log_job_success","text":"summary, job summary","code":""},{"path":"/reference/log_job_success.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log a successful job run — log_job_success","text":"","code":"if (FALSE) {  log_job_success(    summary = \"Job succeeded\"  ) }"},{"path":"/reference/mutate_columns_to_posixct.html","id":null,"dir":"Reference","previous_headings":"","what":"mutate_columns_to_posixct — mutate_columns_to_posixct","title":"mutate_columns_to_posixct — mutate_columns_to_posixct","text":"Mutates column data types POSIXct. Especially useful working -memory tables dates often converted int.","code":""},{"path":"/reference/mutate_columns_to_posixct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mutate_columns_to_posixct — mutate_columns_to_posixct","text":"","code":"mutate_columns_to_posixct(data, column_names)"},{"path":"/reference/mutate_columns_to_posixct.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"mutate_columns_to_posixct — mutate_columns_to_posixct","text":"data - dataframe mutate column_names - vector column names mutate","code":""},{"path":"/reference/mutate_columns_to_posixct.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"mutate_columns_to_posixct — mutate_columns_to_posixct","text":"input dataframe revised data types","code":""},{"path":"/reference/mutate_columns_to_posixct.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"mutate_columns_to_posixct — mutate_columns_to_posixct","text":"","code":"if (FALSE) { time_columns <- c(\"created\", \"updated\") mutate_columns_to_posixct(data, time_columns) }"},{"path":"/reference/quit_non_interactive_run.html","id":null,"dir":"Reference","previous_headings":"","what":"Quit a non interactive R session — quit_non_interactive_run","title":"Quit a non interactive R session — quit_non_interactive_run","text":"Quit non interactive R session","code":""},{"path":"/reference/quit_non_interactive_run.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quit a non interactive R session — quit_non_interactive_run","text":"","code":"quit_non_interactive_run()"},{"path":"/reference/quit_non_interactive_run.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quit a non interactive R session — quit_non_interactive_run","text":"","code":"if (FALSE) {   quit_non_interactive_run() }"},{"path":"/reference/scrape_user_api_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Gather all API tokens on a specified REDCap server for a given user — scrape_user_api_tokens","title":"Gather all API tokens on a specified REDCap server for a given user — scrape_user_api_tokens","text":"Gather API tokens specified REDCap server given user","code":""},{"path":"/reference/scrape_user_api_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gather all API tokens on a specified REDCap server for a given user — scrape_user_api_tokens","text":"","code":"scrape_user_api_tokens(conn, username_to_scrape = Sys.info()[[\"user\"]])"},{"path":"/reference/scrape_user_api_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gather all API tokens on a specified REDCap server for a given user — scrape_user_api_tokens","text":"conn DBI database connection REDCap instance, get_redcap_db_connection username_to_scrape REDCap username, defaults system's username","code":""},{"path":"/reference/scrape_user_api_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gather all API tokens on a specified REDCap server for a given user — scrape_user_api_tokens","text":"dataframe tokens assigned user containing following: project_id - project ID REDCap (0 super token) username - username REDCap token - API token associated project ID project_display_name - name project appears REDCap GUI","code":""},{"path":"/reference/scrape_user_api_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gather all API tokens on a specified REDCap server for a given user — scrape_user_api_tokens","text":"","code":"if (FALSE) {   conn <- get_redcap_db_connection()   my_credentials <- scrape_user_api_tokens(conn, \"admin\")  }"},{"path":"/reference/send_email.html","id":null,"dir":"Reference","previous_headings":"","what":"A wrapper function that sends an email (via sendmailR) reporting the outcome of another function — send_email","title":"A wrapper function that sends an email (via sendmailR) reporting the outcome of another function — send_email","text":"wrapper function sends email (via sendmailR) reporting outcome another function","code":""},{"path":"/reference/send_email.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A wrapper function that sends an email (via sendmailR) reporting the outcome of another function — send_email","text":"","code":"send_email(   email_body,   email_subject = \"\",   email_to = \"\",   email_cc = \"\",   email_from = \"\" )"},{"path":"/reference/send_email.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A wrapper function that sends an email (via sendmailR) reporting the outcome of another function — send_email","text":"email_body contents email email_subject subject line email email_to email addresses primary recipient(s), separate recipient addresses spaces email_cc email addresses cc'd recipient(s), separate recipient addresses spaces email_from email addresses sender","code":""},{"path":"/reference/send_email.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A wrapper function that sends an email (via sendmailR) reporting the outcome of another function — send_email","text":"returned value","code":""},{"path":"/reference/send_email.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A wrapper function that sends an email (via sendmailR) reporting the outcome of another function — send_email","text":"","code":"if (FALSE) { message <- paste(\"Failed REDCap data import to\", project_title,                   \"\\nThe reason given was:\", error_message)  email_subject <- paste(\"FAILED |\", script_name, \"|\",                         Sys.getenv(\"INSTANCE\"), \"|\", script_run_time)  send_email(message, email_subject) }"},{"path":"/reference/set_package_scope_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign a value to the redcapcustodian.env environment, retrievable with get_package_scope_var — set_package_scope_var","title":"Assign a value to the redcapcustodian.env environment, retrievable with get_package_scope_var — set_package_scope_var","text":"Assign value redcapcustodian.env environment, retrievable get_package_scope_var Assign value redcapcustodian.env environment, retrievable get_package_scope_var","code":""},{"path":"/reference/set_package_scope_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign a value to the redcapcustodian.env environment, retrievable with get_package_scope_var — set_package_scope_var","text":"","code":"set_package_scope_var(key, value)  set_package_scope_var(key, value)"},{"path":"/reference/set_package_scope_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign a value to the redcapcustodian.env environment, retrievable with get_package_scope_var — set_package_scope_var","text":"key identifying string store lookup key value value store","code":""},{"path":"/reference/set_package_scope_var.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assign a value to the redcapcustodian.env environment, retrievable with get_package_scope_var — set_package_scope_var","text":"","code":"if (FALSE) {   set_package_scope_var(\"hello\", \"world\")   hello <- get_package_scope_var(\"hello\") } if (FALSE) {   set_package_scope_var(\"hello\", \"world\")   hello <- get_package_scope_var(\"hello\") }"},{"path":"/reference/set_project_api_token.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate an API token for a REDCap project and assign it to a specified user — set_project_api_token","title":"Generate an API token for a REDCap project and assign it to a specified user — set_project_api_token","text":"Generate API token REDCap project assign specified user","code":""},{"path":"/reference/set_project_api_token.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate an API token for a REDCap project and assign it to a specified user — set_project_api_token","text":"","code":"set_project_api_token(conn, username, project_id)"},{"path":"/reference/set_project_api_token.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate an API token for a REDCap project and assign it to a specified user — set_project_api_token","text":"conn DBI database connection, get_redcap_db_connection username REDCap username  user must already access project, .e. must appear project's User Rights project_id project id project wish generate token","code":""},{"path":"/reference/set_project_api_token.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate an API token for a REDCap project and assign it to a specified user — set_project_api_token","text":"nothing","code":""},{"path":"/reference/set_project_api_token.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate an API token for a REDCap project and assign it to a specified user — set_project_api_token","text":"","code":"if (FALSE) {   conn <- get_redcap_db_connection()   my_new_token <- set_project_api_token(conn, \"admin\", 15) }"},{"path":"/reference/set_script_name.html","id":null,"dir":"Reference","previous_headings":"","what":"Assigns package-scoped script_name. \nBy default this is sourced from the focused RStudio window or\nthe calling command (e.g. Rscript script_name.R) — set_script_name","title":"Assigns package-scoped script_name. \nBy default this is sourced from the focused RStudio window or\nthe calling command (e.g. Rscript script_name.R) — set_script_name","text":"Assigns package-scoped script_name.  default sourced focused RStudio window calling command (e.g. Rscript script_name.R)","code":""},{"path":"/reference/set_script_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assigns package-scoped script_name. \nBy default this is sourced from the focused RStudio window or\nthe calling command (e.g. Rscript script_name.R) — set_script_name","text":"","code":"set_script_name(script_name = \"\")"},{"path":"/reference/set_script_name.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assigns package-scoped script_name. \nBy default this is sourced from the focused RStudio window or\nthe calling command (e.g. Rscript script_name.R) — set_script_name","text":"script_name optional arg override calling script","code":""},{"path":"/reference/set_script_run_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets the package-scoped value of script_run_time — set_script_run_time","title":"Sets the package-scoped value of script_run_time — set_script_run_time","text":"Sets package-scoped value script_run_time","code":""},{"path":"/reference/set_script_run_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets the package-scoped value of script_run_time — set_script_run_time","text":"","code":"set_script_run_time(fake_runtime = lubridate::NA_POSIXct_)"},{"path":"/reference/set_script_run_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sets the package-scoped value of script_run_time — set_script_run_time","text":"fake_runtime asserted script run time","code":""},{"path":"/reference/set_script_run_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sets the package-scoped value of script_run_time — set_script_run_time","text":"package-scoped value script_run_time","code":""},{"path":"/reference/set_script_run_time.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sets the package-scoped value of script_run_time — set_script_run_time","text":"","code":"set_script_run_time() #> [1] \"2023-03-20 15:17:39 UTC\" set_script_run_time(fake_runtime =                     as.POSIXct(\"2021-02-23 02:23:00\",                                tz=\"\",                                format=\"%Y-%m-%d %H:%M:%OS\")                    ) #> [1] \"2021-02-23 02:23:00 UTC\""},{"path":"/reference/set_super_api_token.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate and set a Super API token for a provided REDCap user — set_super_api_token","title":"Generate and set a Super API token for a provided REDCap user — set_super_api_token","text":"Generate set Super API token provided REDCap user","code":""},{"path":"/reference/set_super_api_token.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate and set a Super API token for a provided REDCap user — set_super_api_token","text":"","code":"set_super_api_token(conn, username)"},{"path":"/reference/set_super_api_token.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate and set a Super API token for a provided REDCap user — set_super_api_token","text":"conn DBI database connection, get_redcap_db_connection username REDCap username","code":""},{"path":"/reference/set_super_api_token.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate and set a Super API token for a provided REDCap user — set_super_api_token","text":"newly created super token","code":""},{"path":"/reference/set_super_api_token.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate and set a Super API token for a provided REDCap user — set_super_api_token","text":"","code":"if (FALSE) {   conn <- get_redcap_db_connection()   my_new_super_token <- set_super_api_token(conn, \"admin\") }"},{"path":"/reference/suspend_users_with_no_primary_email.html","id":null,"dir":"Reference","previous_headings":"","what":"Suspends users with no primary email in redcap_user_information — suspend_users_with_no_primary_email","title":"Suspends users with no primary email in redcap_user_information — suspend_users_with_no_primary_email","text":"Suspends users primary email redcap_user_information","code":""},{"path":"/reference/suspend_users_with_no_primary_email.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Suspends users with no primary email in redcap_user_information — suspend_users_with_no_primary_email","text":"","code":"suspend_users_with_no_primary_email(conn)"},{"path":"/reference/suspend_users_with_no_primary_email.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Suspends users with no primary email in redcap_user_information — suspend_users_with_no_primary_email","text":"conn DBI Connection object","code":""},{"path":"/reference/suspend_users_with_no_primary_email.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Suspends users with no primary email in redcap_user_information — suspend_users_with_no_primary_email","text":"","code":"if (FALSE) { suspend_users_with_no_primary_email(conn) }"},{"path":"/reference/sync_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Sync data dictionary of a source project to a target project using credential objects — sync_metadata","title":"Sync data dictionary of a source project to a target project using credential objects — sync_metadata","text":"Sync data dictionary source project target project using credential objects","code":""},{"path":"/reference/sync_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sync data dictionary of a source project to a target project using credential objects — sync_metadata","text":"","code":"sync_metadata(   source_credentials,   target_credentials,   strip_action_tags = FALSE )"},{"path":"/reference/sync_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sync data dictionary of a source project to a target project using credential objects — sync_metadata","text":"source_credentials dataframe containing following columns: redcap_uri - uri API endpoint REDCap host token - REDCap API token specific project dataframe contain credentials project wish copy target_credentials dataframe containing following columns: redcap_uri - uri API endpoint REDCap host token - REDCap API token specific project dataframe contain credentials project wish overwrite strip_action_tags Optional toggle remove action tags, useful porting development environment; defaults FALSE","code":""},{"path":"/reference/sync_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sync data dictionary of a source project to a target project using credential objects — sync_metadata","text":"nothing","code":""},{"path":[]},{"path":"/reference/sync_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sync data dictionary of a source project to a target project using credential objects — sync_metadata","text":"","code":"if (FALSE) {   source_credentials <- REDCapR::retrieve_credential_local(     path_credential = \"source_credentials.csv\",     project_id = 31   )    target_credentials <- REDCapR::retrieve_credential_local(     path_credential = \"target_credentials.csv\",     project_id = 25   )    sync_metadata(source_credentials, target_credentials) }"},{"path":"/reference/sync_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Write to a MySQL Database using the result of dataset_diff — sync_table","title":"Write to a MySQL Database using the result of dataset_diff — sync_table","text":"Write MySQL Database using result dataset_diff","code":""},{"path":"/reference/sync_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write to a MySQL Database using the result of dataset_diff — sync_table","text":"","code":"sync_table(   conn,   table_name,   primary_key,   data_diff_output,   insert = F,   update = T,   delete = F )"},{"path":"/reference/sync_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write to a MySQL Database using the result of dataset_diff — sync_table","text":"conn DBI database connection table_name name table write primary_key name primary key (vector multiple keys) table write data_diff_output list dataframes returned dataset_diff insert boolean toggle use insert dataframe insert rows table_name update boolean toggle use updates dataframe update rows table_name delete boolean toggle use delete dataframe delete rows table_name","code":""},{"path":"/reference/sync_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write to a MySQL Database using the result of dataset_diff — sync_table","text":"named list values: insert_n - number rows inserted table_name update_n - number rows updated table_name delete_n - number rows deleted table_name","code":""},{"path":"/reference/sync_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write to a MySQL Database using the result of dataset_diff — sync_table","text":"","code":"if (FALSE) { conn <- connect_to_redcap_db()   ...  diff_output <- dataset_diff(   source = updates,   source_pk = \"id\",   target = original_table,   target_pk = \"id\" )  sync_table(   conn = con,   table_name = table_name,   primary_key = primary_key,   data_diff_output = diff_output ) }"},{"path":"/reference/sync_table_2.html","id":null,"dir":"Reference","previous_headings":"","what":"Write to a MySQL Database based on the diff of source and target datasets. — sync_table_2","title":"Write to a MySQL Database based on the diff of source and target datasets. — sync_table_2","text":"Write MySQL Database based diff source target datasets.","code":""},{"path":"/reference/sync_table_2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write to a MySQL Database based on the diff of source and target datasets. — sync_table_2","text":"","code":"sync_table_2(   conn,   table_name,   source,   source_pk,   target,   target_pk,   insert = F,   update = T,   delete = F )"},{"path":"/reference/sync_table_2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write to a MySQL Database based on the diff of source and target datasets. — sync_table_2","text":"conn DBI database connection table_name name table write source - dataframe content needs reflected target source_pk - primary key source target - data frame needs reflect source target_pk - primary key target insert boolean toggle use insert dataframe insert rows table_name update boolean toggle use updates dataframe update rows table_name delete boolean toggle use delete dataframe delete rows table_name","code":""},{"path":"/reference/sync_table_2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write to a MySQL Database based on the diff of source and target datasets. — sync_table_2","text":"named list values: insert_records - dataframe inserts update_records - dataframe updates delete_records - dataframe deletions insert_n - number rows inserted table_name update_n - number rows updated table_name delete_n - number rows deleted table_name","code":""},{"path":"/reference/sync_table_2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write to a MySQL Database based on the diff of source and target datasets. — sync_table_2","text":"","code":"if (FALSE) { conn <- connect_to_redcap_db()   ...  sync_table_2(   conn = con,   table_name = table_name,   source = updates,   source_pk = \"id\",   target = original_table,   target_pk = \"id\" ) }"},{"path":"/reference/sync_table_test_user_data_result.html","id":null,"dir":"Reference","previous_headings":"","what":"sync_table_test_user_data_result — sync_table_test_user_data_result","title":"sync_table_test_user_data_result — sync_table_test_user_data_result","text":"output sync_table dataset_diff_test_user_data used input","code":""},{"path":"/reference/sync_table_test_user_data_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"sync_table_test_user_data_result — sync_table_test_user_data_result","text":"","code":"sync_table_test_user_data_result"},{"path":"/reference/sync_table_test_user_data_result.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"sync_table_test_user_data_result — sync_table_test_user_data_result","text":"data frame 4 rows 3 variables: ui_id double primary key username character redcap username user_email character primary email address","code":""},{"path":"/reference/sync_table_test_user_data_result.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"sync_table_test_user_data_result — sync_table_test_user_data_result","text":"DETAILS","code":""},{"path":"/reference/update_production_allocation_state.html","id":null,"dir":"Reference","previous_headings":"","what":"update_production_allocation_state — update_production_allocation_state","title":"update_production_allocation_state — update_production_allocation_state","text":"Update producition rows redcap_randomization_allocation table   mirror another project.","code":""},{"path":"/reference/update_production_allocation_state.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"update_production_allocation_state — update_production_allocation_state","text":"","code":"update_production_allocation_state(   source_conn,   target_conn,   source_project_id,   target_rid )"},{"path":"/reference/update_production_allocation_state.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"update_production_allocation_state — update_production_allocation_state","text":"source_conn - DBI connection object pointing REDCap database houses source project. target_conn - DBI connection object pointing REDCap database houses target project. source_project_id - project ID REDCap project contains randomization cloned. target_rid - randomization id REDCap project receive updated randomization data.","code":""},{"path":"/reference/update_production_allocation_state.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"update_production_allocation_state — update_production_allocation_state","text":"- list output sync_table_2 update   randomization allocation table.","code":""},{"path":"/reference/update_production_allocation_state.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"update_production_allocation_state — update_production_allocation_state","text":"","code":"if (FALSE) { target_project_allocation_update <- update_production_allocation_state(   source_conn = source_conn,   target_conn = target_conn,   source_project_id = source_project_id,   target_rid = target_project_randomization_state$rid ) }"},{"path":"/reference/update_redcap_email_addresses.html","id":null,"dir":"Reference","previous_headings":"","what":"Updates bad redcap email addresses in redcap_user_information — update_redcap_email_addresses","title":"Updates bad redcap email addresses in redcap_user_information — update_redcap_email_addresses","text":"Updates bad redcap email addresses redcap_user_information","code":""},{"path":"/reference/update_redcap_email_addresses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Updates bad redcap email addresses in redcap_user_information — update_redcap_email_addresses","text":"","code":"update_redcap_email_addresses(   conn,   redcap_email_revisions,   redcap_email_original )"},{"path":"/reference/update_redcap_email_addresses.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Updates bad redcap email addresses in redcap_user_information — update_redcap_email_addresses","text":"conn DBI Connection object redcap_email_revisions df returned get_redcap_email_revisions redcap_email_original df original redcap_user_information email data","code":""},{"path":"/reference/update_redcap_email_addresses.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Updates bad redcap email addresses in redcap_user_information — update_redcap_email_addresses","text":"","code":"if (FALSE) { conn <- connect_to_redcap_db() bad_emails <- get_bad_emails_from_listserv_digest(   username = \"jdoe\",   password = \"jane_does_password\",   url = \"imaps://outlook.office365.com\",   messages_since_date = as.Date(\"2022-01-01\", format = \"%Y-%m-%d\") ) bad_redcap_user_emails <- get_redcap_emails(conn)$tall %>%   filter(email %in% bad_emails)  person_data <- get_institutional_person_data() redcap_email_revisions <- get_redcap_email_revisions(bad_redcap_email_output, person_data)  update_redcap_email_addresses(   conn,   redcap_email_revisions,   redcap_email_original = get_redcap_emails(conn)$wide ) }"},{"path":"/reference/update_redcap_email_addresses_test_data.html","id":null,"dir":"Reference","previous_headings":"","what":"update_redcap_email_addresses_test_data — update_redcap_email_addresses_test_data","title":"update_redcap_email_addresses_test_data — update_redcap_email_addresses_test_data","text":"list test inputs outputs update_redcap_email_addresses","code":""},{"path":"/reference/update_redcap_email_addresses_test_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"update_redcap_email_addresses_test_data — update_redcap_email_addresses_test_data","text":"","code":"update_redcap_email_addresses_test_data"},{"path":"/reference/update_redcap_email_addresses_test_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"update_redcap_email_addresses_test_data — update_redcap_email_addresses_test_data","text":"list 1 variables: output tibble email data read backfrom redcap_user_information","code":""},{"path":"/reference/update_redcap_email_addresses_test_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"update_redcap_email_addresses_test_data — update_redcap_email_addresses_test_data","text":"DETAILS","code":""},{"path":"/reference/user_rights_test_data.html","id":null,"dir":"Reference","previous_headings":"","what":"user_rights_test_data — user_rights_test_data","title":"user_rights_test_data — user_rights_test_data","text":"named list dataframes used test functions written manage user rights","code":""},{"path":"/reference/user_rights_test_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"user_rights_test_data — user_rights_test_data","text":"","code":"user_rights_test_data"},{"path":"/reference/user_rights_test_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"user_rights_test_data — user_rights_test_data","text":"named list 3 dataframes: redcap_user_information REDCap Core table redcap_user_rights REDCap Core table redcap_user_roles REDCap Core table","code":""},{"path":"/reference/user_rights_test_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"user_rights_test_data — user_rights_test_data","text":"DETAILS","code":""},{"path":"/reference/verify_log_connectivity.html","id":null,"dir":"Reference","previous_headings":"","what":"Attempts to connect to the DB using all LOG_DB_* environment variables. Returns an empty list if a connection is established, returns an `error_list` entry otherwise. — verify_log_connectivity","title":"Attempts to connect to the DB using all LOG_DB_* environment variables. Returns an empty list if a connection is established, returns an `error_list` entry otherwise. — verify_log_connectivity","text":"Attempts connect DB using LOG_DB_* environment variables. Returns empty list connection established, returns `error_list` entry otherwise.","code":""},{"path":"/reference/verify_log_connectivity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Attempts to connect to the DB using all LOG_DB_* environment variables. Returns an empty list if a connection is established, returns an `error_list` entry otherwise. — verify_log_connectivity","text":"","code":"verify_log_connectivity(drv = RMariaDB::MariaDB())"},{"path":"/reference/verify_log_connectivity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Attempts to connect to the DB using all LOG_DB_* environment variables. Returns an empty list if a connection is established, returns an `error_list` entry otherwise. — verify_log_connectivity","text":"drv, object inherits DBIDriver (e.g. RMariaDB::MariaDB()), existing DBIConnection object (order clone existing connection).","code":""},{"path":"/reference/verify_log_connectivity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Attempts to connect to the DB using all LOG_DB_* environment variables. Returns an empty list if a connection is established, returns an `error_list` entry otherwise. — verify_log_connectivity","text":"`error_list` entry","code":""},{"path":"/reference/verify_log_connectivity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Attempts to connect to the DB using all LOG_DB_* environment variables. Returns an empty list if a connection is established, returns an `error_list` entry otherwise. — verify_log_connectivity","text":"","code":"if (FALSE) {  verify_log_connectivity(RMariaDB::MariaDB()) }"},{"path":"/reference/verify_log_dependencies.html","id":null,"dir":"Reference","previous_headings":"","what":"Verifies all dependencies required to write log entries. — verify_log_dependencies","title":"Verifies all dependencies required to write log entries. — verify_log_dependencies","text":"Verifies dependencies required write log entries.","code":""},{"path":"/reference/verify_log_dependencies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verifies all dependencies required to write log entries. — verify_log_dependencies","text":"","code":"verify_log_dependencies(drv = RMariaDB::MariaDB())"},{"path":"/reference/verify_log_dependencies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Verifies all dependencies required to write log entries. — verify_log_dependencies","text":"drv, object inherits DBIDriver (e.g. RMariaDB::MariaDB()), existing DBIConnection object (order clone existing connection).","code":""},{"path":"/reference/verify_log_dependencies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verifies all dependencies required to write log entries. — verify_log_dependencies","text":"list `error_list` entries.","code":""},{"path":"/reference/verify_log_dependencies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verifies all dependencies required to write log entries. — verify_log_dependencies","text":"","code":"if (FALSE) {  verify_log_dependencies(      drv = RMariaDB::MariaDB()  ) }"},{"path":"/reference/verify_log_env_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Verifies all required environment variables are set. Returns an empty list if all necessary environment variables are set, returns a list of errors otherwise. — verify_log_env_variables","title":"Verifies all required environment variables are set. Returns an empty list if all necessary environment variables are set, returns a list of errors otherwise. — verify_log_env_variables","text":"Verifies required environment variables set. Returns empty list necessary environment variables set, returns list errors otherwise.","code":""},{"path":"/reference/verify_log_env_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verifies all required environment variables are set. Returns an empty list if all necessary environment variables are set, returns a list of errors otherwise. — verify_log_env_variables","text":"","code":"verify_log_env_variables()"},{"path":"/reference/verify_log_env_variables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Verifies all required environment variables are set. Returns an empty list if all necessary environment variables are set, returns a list of errors otherwise. — verify_log_env_variables","text":"list `error_list` entries.","code":""},{"path":"/reference/verify_log_env_variables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Verifies all required environment variables are set. Returns an empty list if all necessary environment variables are set, returns a list of errors otherwise. — verify_log_env_variables","text":"","code":"if (FALSE) {  verify_log_env_variables() }"},{"path":"/reference/write_allocations.html","id":null,"dir":"Reference","previous_headings":"","what":"write_allocations — write_allocations","title":"write_allocations — write_allocations","text":"Write development production randomization allocation table   form loaded.","code":""},{"path":"/reference/write_allocations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"write_allocations — write_allocations","text":"","code":"write_allocations(project_status_to_write, allocations, target_directory = \".\")"},{"path":"/reference/write_allocations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"write_allocations — write_allocations","text":"project_status_to_write - value project_status export. Use 0 development. Use 1 Production allocations - dataframe randomization allocation data exported `export_allocation_tables_from_project` target_directory - directory function write files","code":""},{"path":"/reference/write_allocations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"write_allocations — write_allocations","text":"full path allocations file","code":""},{"path":"/reference/write_allocations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"write_allocations — write_allocations","text":"","code":"if (FALSE) { # get and print importable allocations if we need them for reference allocations <- export_allocation_tables_from_project(   conn = source_conn,   project_id_to_export = source_project_id )  # write both files walk(c(0,1), write_allocations, allocations, \"output\") }"},{"path":"/reference/write_debug_job_log_entry.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a debug log entry for the job — write_debug_job_log_entry","title":"Write a debug log entry for the job — write_debug_job_log_entry","text":"Write debug log entry job","code":""},{"path":"/reference/write_debug_job_log_entry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a debug log entry for the job — write_debug_job_log_entry","text":"","code":"write_debug_job_log_entry(con, job_duration, job_summary)"},{"path":"/reference/write_debug_job_log_entry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a debug log entry for the job — write_debug_job_log_entry","text":"con, DB connection job_duration, duration job seconds job_summary, summary job performed JSON","code":""},{"path":"/reference/write_debug_job_log_entry.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write a debug log entry for the job — write_debug_job_log_entry","text":"","code":"if (FALSE) {  write_debug_job_log_entry(    conn = con,    job_duration = 30,    job_summary = as.json(\"Update vaccination status\")  ) }"},{"path":"/reference/write_error_job_log_entry.html","id":null,"dir":"Reference","previous_headings":"","what":"Write an error log entry for the job — write_error_job_log_entry","title":"Write an error log entry for the job — write_error_job_log_entry","text":"Write error log entry job","code":""},{"path":"/reference/write_error_job_log_entry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write an error log entry for the job — write_error_job_log_entry","text":"","code":"write_error_job_log_entry(con, job_duration, job_summary)"},{"path":"/reference/write_error_job_log_entry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write an error log entry for the job — write_error_job_log_entry","text":"con, DB connection job_duration, duration job seconds job_summary, summary job performed JSON","code":""},{"path":"/reference/write_error_job_log_entry.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write an error log entry for the job — write_error_job_log_entry","text":"","code":"if (FALSE) {  write_error_job_log_entry(    conn = con,    job_duration = 30,    job_summary = as.json(\"Update vaccination status\")  ) }"},{"path":"/reference/write_error_log_entry.html","id":null,"dir":"Reference","previous_headings":"","what":"Write an error log entry — write_error_log_entry","title":"Write an error log entry — write_error_log_entry","text":"Write error log entry","code":""},{"path":"/reference/write_error_log_entry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write an error log entry — write_error_log_entry","text":"","code":"write_error_log_entry(conn, target_db_name, table_written = NULL, df, pk_col)"},{"path":"/reference/write_error_log_entry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write an error log entry — write_error_log_entry","text":"conn, DB connection target_db_name, database write table_written, table written df, data write pk_col, dataframe col use primary_key","code":""},{"path":[]},{"path":"/reference/write_info_log_entry.html","id":null,"dir":"Reference","previous_headings":"","what":"Write an info log entry — write_info_log_entry","title":"Write an info log entry — write_info_log_entry","text":"Write info log entry","code":""},{"path":"/reference/write_info_log_entry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write an info log entry — write_info_log_entry","text":"","code":"write_info_log_entry(conn, target_db_name, table_written = NULL, df, pk_col)"},{"path":"/reference/write_info_log_entry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write an info log entry — write_info_log_entry","text":"conn, DB connection target_db_name, database write table_written, table written df, data write pk_col, dataframe col use primary_key","code":""},{"path":"/reference/write_info_log_entry.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write an info log entry — write_info_log_entry","text":"","code":"if (FALSE) {  write_info_log_entry(    conn = con,    target_db_name = rc_case,    table_written = \"cases\",    df = data_written,    pk_col = \"record_id\",  ) }"},{"path":"/reference/write_success_job_log_entry.html","id":null,"dir":"Reference","previous_headings":"","what":"Write an success job log entry — write_success_job_log_entry","title":"Write an success job log entry — write_success_job_log_entry","text":"Write success job log entry","code":""},{"path":"/reference/write_success_job_log_entry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write an success job log entry — write_success_job_log_entry","text":"","code":"write_success_job_log_entry(con, job_duration, job_summary)"},{"path":"/reference/write_success_job_log_entry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write an success job log entry — write_success_job_log_entry","text":"con, DB connection job_duration, duration job seconds job_summary, summary job performed JSON","code":""},{"path":"/reference/write_success_job_log_entry.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write an success job log entry — write_success_job_log_entry","text":"","code":"if (FALSE) {  write_success_job_log_entry(    conn = con,    job_duration = 30,    job_summary = as.json(\"Update vaccination status\")  ) }"},{"path":"/reference/write_summary_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Format and write summary metrics to the redcap_summary_metrics table in your LOG_DB — write_summary_metrics","title":"Format and write summary metrics to the redcap_summary_metrics table in your LOG_DB — write_summary_metrics","text":"Format write summary metrics redcap_summary_metrics table LOG_DB","code":""},{"path":"/reference/write_summary_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format and write summary metrics to the redcap_summary_metrics table in your LOG_DB — write_summary_metrics","text":"","code":"write_summary_metrics(   reporting_period_start,   reporting_period_end,   metric_type,   metric_dataframe )"},{"path":"/reference/write_summary_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format and write summary metrics to the redcap_summary_metrics table in your LOG_DB — write_summary_metrics","text":"reporting_period_start datetime object, e.g. ymd_hms(\"2022-11-01 00:00:00\") reporting_period_end datetime object, e.g. ymd_hms(\"2022-12-01 00:00:00\") metric_type character string representing metric type, e.g. \"flux\", \"state\" metric_dataframe wide data frame key-value pairs single row data","code":""},{"path":"/reference/write_summary_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format and write summary metrics to the redcap_summary_metrics table in your LOG_DB — write_summary_metrics","text":"nothing","code":""},{"path":[]},{"path":"/reference/write_to_sql_db.html","id":null,"dir":"Reference","previous_headings":"","what":"Write to a MySQL Database with error checking and email alerting on failure — write_to_sql_db","title":"Write to a MySQL Database with error checking and email alerting on failure — write_to_sql_db","text":"Write MySQL Database error checking email alerting failure","code":""},{"path":"/reference/write_to_sql_db.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write to a MySQL Database with error checking and email alerting on failure — write_to_sql_db","text":"","code":"write_to_sql_db(   conn,   table_name,   df_to_write,   schema,   overwrite,   db_name,   is_log_con = FALSE,   continue_on_error = FALSE,   ... )"},{"path":"/reference/write_to_sql_db.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write to a MySQL Database with error checking and email alerting on failure — write_to_sql_db","text":"conn DBI database connection table_name name table write df_to_write data frame write _table_name_ schema database write overwrite logical controls whether overwrite table db_name name database written is_log_con FALSE log failures, TRUE attempt log errors continue_on_error TRUE continue execution error, FALSE quit non interactive sessions error ... Additional parameters passed DBI::dbWriteTable","code":""},{"path":"/reference/write_to_sql_db.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write to a MySQL Database with error checking and email alerting on failure — write_to_sql_db","text":"value returned","code":""},{"path":[]},{"path":"/news/index.html","id":"version-181-released-2023-03-20","dir":"Changelog","previous_headings":"","what":"Version 1.8.1 (released 2023-03-20)","title":"Version 1.8.1 (released 2023-03-20)","text":"Update NEWS.md DESCRIPTION comply pkgdown (@pbchase, #103)","code":""},{"path":[]},{"path":"/news/index.html","id":"added-1-8-0","dir":"Changelog","previous_headings":"","what":"Added","title":"Version 1.8.0 (released 2023-03-17)","text":"Add log database system dev work (@pbchase)","code":""},{"path":"/news/index.html","id":"changed-1-8-0","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 1.8.0 (released 2023-03-17)","text":"Fix ORCIDs DESCRIPTION (@pbchase)","code":""},{"path":[]},{"path":"/news/index.html","id":"added-1-7-0","dir":"Changelog","previous_headings":"","what":"Added","title":"Version 1.7.0 (released 2023-03-17)","text":"Add pkgdown website (@pbchase)","code":""},{"path":"/news/index.html","id":"changed-1-7-0","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 1.7.0 (released 2023-03-17)","text":"Revise package title away REDCap towards automation (@pbchase) Remove publication_date .zenodo.json (@pbchase)","code":""},{"path":[]},{"path":"/news/index.html","id":"added-1-6-0","dir":"Changelog","previous_headings":"","what":"Added","title":"Version 1.6.0 (released 2023-02-21)","text":"Add randomization management functions sample ETL (@pbchase) Add batch_size parm dbx calls sync_table_2 (@pbchase) Add batch_size parm dbx calls sync_table Prevents possible error: Expression tree large (maximum depth 1000) (@ChemiKyle)","code":""},{"path":"/news/index.html","id":"changed-1-6-0","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 1.6.0 (released 2023-02-21)","text":"Update testing image used github (@pbchase) Eschew deprecated tidyselect features (@pbchase) Modernize tests sync_table_2 (@pbchase) Address fatal bug sync_table caused delete = T records delete (@ChemiKyle)","code":""},{"path":[]},{"path":"/news/index.html","id":"added-1-5-0","dir":"Changelog","previous_headings":"","what":"Added","title":"Version 1.5.0 (released 2023-01-25)","text":"Create write_summary_metrics function, corresponding schema test (@ChemiKyle) Add render_report /report (@ljwoodley) Port convert_schema_to_sqlite rcc.billing, altering accept path sql file input (@ChemiKyle) Port mutate_columns_to_posixct rcc.billing (@ChemiKyle)","code":""},{"path":"/news/index.html","id":"changed-1-5-0","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 1.5.0 (released 2023-01-25)","text":"Ignore local credentials DBs (@pbchase)","code":""},{"path":[]},{"path":"/news/index.html","id":"changed-1-4-1","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 1.4.1 (released 2022-12-15)","text":"Install latex packages directly Dockerfile (@ljwoodley)","code":""},{"path":[]},{"path":"/news/index.html","id":"added-1-4-0","dir":"Changelog","previous_headings":"","what":"Added","title":"Version 1.4.0 (released 2022-12-13)","text":"Switch Dockerfile tidyverse verse (@ljwoodley) Add render_report.R render Rmds (@ljwoodley)","code":""},{"path":[]},{"path":"/news/index.html","id":"changed-1-3-2","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 1.3.2 (released 2022-09-14)","text":"Specify package na.exclude() (@pbchase) escape . treat literal character instead wildcard gsub statements (@ChemiKyle)","code":""},{"path":[]},{"path":"/news/index.html","id":"added-1-3-1","dir":"Changelog","previous_headings":"","what":"Added","title":"Version 1.3.1 (released 2022-08-30)","text":"Remove remants site concept (@pbchase)","code":""},{"path":[]},{"path":"/news/index.html","id":"added-1-3-0","dir":"Changelog","previous_headings":"","what":"Added","title":"Version 1.3.0 (released 2022-08-29)","text":"Add get_bad_emails_from_individual_emails function (@ChemiKyle)","code":""},{"path":[]},{"path":"/news/index.html","id":"changed-1-2-2","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 1.2.2 (released 2022-08-26)","text":"Modernize container add dependencies (@pbchase)","code":""},{"path":[]},{"path":"/news/index.html","id":"changed-1-2-1","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 1.2.1 (released 2022-08-26)","text":"Move schema files package space (@pbchase) Correct send_email using email_to email_cc (@ChemiKyle)","code":""},{"path":[]},{"path":"/news/index.html","id":"added-1-2-0","dir":"Changelog","previous_headings":"","what":"Added","title":"Version 1.2.0 (released 2022-08-25)","text":"Add email_from email_cc params send_email function, default env value (@ChemiKyle)","code":""},{"path":[]},{"path":"/news/index.html","id":"changed-1-1-1","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 1.1.1 (released 2022-08-24)","text":"Fix test search results get_bad_emails_from_listserv_digest (@pbchase)","code":""},{"path":[]},{"path":"/news/index.html","id":"added-1-1-0","dir":"Changelog","previous_headings":"","what":"Added","title":"Version 1.1.0 (released 2022-08-08)","text":"Add logging Friday Call demo (@pbchase)","code":""},{"path":"/news/index.html","id":"changed-1-1-0","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 1.1.0 (released 2022-08-08)","text":"Define username tube count variables friday call demo (@ChemiKyle) Move fake data section setup file Friday Call Demo (@pbchase) Move credential creation scraping main friday call auxiliary setup file (@ChemiKyle)","code":""},{"path":[]},{"path":"/news/index.html","id":"added-1-0-0","dir":"Changelog","previous_headings":"","what":"Added","title":"Version 1.0.0 (released 2022-08-02)","text":"Add logging suspend_users_with_no_primary_email (@pbchase) Add sync_table2 merge dataset_diff sync_table (@pbchase) Add expire_user_project_rights (@pbchase)","code":""},{"path":"/news/index.html","id":"changed-1-0-0","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 1.0.0 (released 2022-08-02)","text":"Use sync_table_2 update_redcap_email_addresses (@pbchase) Refactor tests test data related cleanup_bad_email_addresses.R (@pbchase) Remove credentials public image (@mbentz-uf) Fix deployment cron file (@pbchase) Add common directories template ignore files (@pbchase) Fix ADD .study (@pbchase)","code":""},{"path":[]},{"path":"/news/index.html","id":"changed-0-7-0","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 0.7.0 (released 2022-07-17)","text":"Add package Dockerfile (@pbchase) Add send_email function adapted stp (@ChemiKyle) Add DOI badge README (@pbchase)","code":""},{"path":[]},{"path":"/news/index.html","id":"changed-0-6-1","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 0.6.1 (released 2022-07-13)","text":"Fix typo description (@pbchase)","code":""},{"path":[]},{"path":"/news/index.html","id":"added-0-6-0","dir":"Changelog","previous_headings":"","what":"Added","title":"Version 0.6.0 (released 2022-07-13)","text":"Add resources publication (@pbchase) Add friday-call-demo.Rmd (@ChemiKyle, @pbchase)","code":""},{"path":"/news/index.html","id":"changed-0-6-0","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 0.6.0 (released 2022-07-13)","text":"Update ignore files respect new features (@pbchase) Replace reference stp rcc.billing (@ChemiKyle) Enlarge job_summary_data field rcc_job_log (@pbchase) Add new content custom_rscript (@pbchase) Make docs study-centric (@pbchase) Update DESCRIPTION init_etl.Rd satisfy R 4.2.1 (@pbchase) Use *_PORT_DB connect_to_db, defaulting 3306 (@ChemiKyle) Move credentials DB (@pbchase) Reduce earliest_date cleanup_bad_email_addresses.R (@pbchase) Use MariaDB default driver init_etl (@pbchase) Update username my_username avoid tautological filter credential gathering (@ChemiKyle)","code":""},{"path":[]},{"path":"/news/index.html","id":"changed-0-5-1","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 0.5.1 (released 2022-06-24)","text":"Export email-fixing functions (@pbchase)","code":""},{"path":[]},{"path":"/news/index.html","id":"added-0-5-0","dir":"Changelog","previous_headings":"","what":"Added","title":"Version 0.5.0 (released 2022-06-23)","text":"Add first version demonstration script (@pbchase) Add sync_table (@ChemiKyle) Add dataset_diff (@pbchase) Add multi_instance.R (@ChemiKyle) Add sync_metadata using credentials (@ChemiKyle) Add scrape_user_api_tokens (@ChemiKyle) Add set_super_api_token (@ChemiKyle) Add set_project_api_token (@ChemiKyle) Add ETL job logging(@mbentz-uf) Add cleanup_bad_email_addresses (@ljwoodley)","code":""},{"path":"/news/index.html","id":"changed-0-5-0","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 0.5.0 (released 2022-06-23)","text":"Ignore site_template build (@pbchase) Ignore ./output/ (@pbchase)","code":""},{"path":[]},{"path":"/news/index.html","id":"changed-0-4-1","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 0.4.1 (released 2022-03-04)","text":"Fix build.sh deployment bugs (@pbchase)","code":""},{"path":[]},{"path":"/news/index.html","id":"added-0-4-0","dir":"Changelog","previous_headings":"","what":"Added","title":"Version 0.4.0 (released 2022-03-03)","text":"Remove host image concet deploy site project (@pbchase)","code":""},{"path":[]},{"path":"/news/index.html","id":"added-0-3-0","dir":"Changelog","previous_headings":"","what":"Added","title":"Version 0.3.0 (released 2022-03-03)","text":"Add mRpostman writexl Dockerfile (@pbchase) Add suspend_users_with_no_primary_email (@ljwoodley) Add update_redcap_email_addresses (@ljwoodley)","code":""},{"path":"/news/index.html","id":"changed-0-3-0","dir":"Changelog","previous_headings":"","what":"Changed","title":"Version 0.3.0 (released 2022-03-03)","text":"Fix get_redcap_email_revisions match initial implementation allows create data result user suspension (@ChemiKyle)","code":""},{"path":[]},{"path":"/news/index.html","id":"added-0-2-0","dir":"Changelog","previous_headings":"","what":"Added","title":"Version 0.2.0 (released 2022-02-16)","text":"Add get_redcap_email_revisions (@mbentz-uf) Add automated tests (@mbentz-uf) Add create_test_tables (@ChemiKyle) Add test tables (@ChemiKyle) Add get_bad_emails_from_listserv_digest (@pbchase) Add get_institutional_person_data (@pbchase) Add get_redcap_emails (@pbchase) Add create_test_table (@pbchase) Add site concept docs (@pbchase) Add add_get_redcap_db_connection (@pbchase) Store rc_conn env (@pbchase) Add add_connect_to_redcap_db (@pbchase) Add basic logging (@mbentz-uf)","code":""},{"path":[]},{"path":"/news/index.html","id":"summary-0-1-0","dir":"Changelog","previous_headings":"","what":"Summary","title":"Version 0.1.0 (released 2021-06-22)","text":"Initial commit redcapcustodian Scripted image building. Scripted deployment. redcapcustodian R package testthat redcapcustodian tests Host-specific customization R scripts Host-specific customization cron-files Host-specific customization environment files","code":""}]
